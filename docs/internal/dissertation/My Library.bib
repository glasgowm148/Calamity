
@article{abdelhaqEvenTweetOnlineLocalized2013,
  ids = {abdelhaqEvenTweetOnlineLocalized},
  title = {{{EvenTweet}}: Online Localized Event Detection from Twitter},
  shorttitle = {{{EvenTweet}}},
  author = {Abdelhaq, Hamed and Sengstock, Christian and Gertz, Michael},
  date = {2013-08-28},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {6},
  pages = {1326--1329},
  issn = {2150-8097},
  doi = {10.14778/2536274.2536307},
  url = {https://dl.acm.org/doi/10.14778/2536274.2536307},
  urldate = {2021-02-09},
  abstract = {Microblogging services such as Twitter, Facebook, and Foursquare have become major sources for information about real-world events. Most approaches that aim at extracting event information from such sources typically use the temporal context of messages. However, exploiting the location information of georeferenced messages, too, is important to detect localized events, such as public events or emergency situations. Users posting messages that are close to the location of an event serve as human sensors to describe an event. In this demonstration, we present a novel framework to detect localized events in real-time from a Twitter stream and to track the evolution of such events over time. For this, spatio-temporal characteristics of keywords are continuously extracted to identify meaningful candidates for event descriptions. Then, localized event information is extracted by clustering keywords according to their spatial similarity. To determine the most important events in a (recent) time frame, we introduce a scoring scheme for events. We demonstrate the functionality of our system, called EvenTweet, using a stream of tweets from Europe during the 2012 UEFA European Football Championship.},
  file = {/Users/mark/Zotero/storage/9ZNLJKDX/Abdelhaq et al. - EvenTweet Online Localized Event Detection from T.pdf;/Users/mark/Zotero/storage/XZQ8XPB5/Abdelhaq et al. - 2013 - EvenTweet online localized event detection from t.pdf},
  langid = {english},
  number = {12}
}

@article{atefehSurveyTechniquesEvent2015,
  ids = {atefehSurveyTechniquesEvent2015a},
  title = {A {{Survey}} of {{Techniques}} for {{Event Detection}} in {{Twitter}}: {{TECHNIQUES FOR EVENT DETECTION IN TWITTER}}},
  shorttitle = {A {{Survey}} of {{Techniques}} for {{Event Detection}} in {{Twitter}}},
  author = {Atefeh, Farzindar and Khreich, Wael},
  date = {2015-02},
  journaltitle = {Computational Intelligence},
  shortjournal = {Computational Intelligence},
  volume = {31},
  pages = {132--164},
  issn = {08247935},
  doi = {10.1111/coin.12017},
  url = {http://doi.wiley.com/10.1111/coin.12017},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/EJ7T65VM/Atefeh and Khreich - 2015 - A Survey of Techniques for Event Detection in Twit.pdf;/Users/mark/Zotero/storage/XLYJDANL/Atefeh and Khreich - 2015 - A Survey of Techniques for Event Detection in Twit.pdf},
  langid = {english},
  number = {1}
}

@inproceedings{avvenutiEarthquakeEmergencyManagement2014,
  ids = {avvenutiEarthquakeEmergencyManagement2014a},
  title = {Earthquake Emergency Management by Social Sensing},
  booktitle = {2014 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communication Workshops}} ({{PERCOM WORKSHOPS}})},
  author = {Avvenuti, Marco and Cresci, Stefano and La Polla, Mariantonietta N. and Marchetti, Andrea and Tesconi, Maurizio},
  date = {2014-03},
  pages = {587--592},
  publisher = {{IEEE}},
  location = {{Budapest, Hungary}},
  doi = {10.1109/PerComW.2014.6815272},
  url = {http://ieeexplore.ieee.org/document/6815272/},
  urldate = {2021-02-09},
  abstract = {Social Sensing is based on the idea that communities or groups of people provide a set of information similar to those obtainable from a single sensor. This amount of information generate a complex and adequate knowledge of one or more specific issues. A possible field of application for Social Sensing is Emergency Management. By using the Social Media it is possible to gather updated information about emerging situations of danger, in order to gain greater situational awareness and to alert interested parties promptly or verify information obtained through other channels. A system able to timely detect events that are of social concern can be referred to as an Early Warning system. In this work we propose a novel and general architecture for an early warning system and, as a proof-ofconcept, we describe an implementation of this architecture for a real scenario. We use Twitter as source of information for the detection of earthquakes on the Italian territory. We compare our results with official data provided by the National Institute of Geophysics and Volcanology, the authority responsible for the monitoring of seismic events in Italy. Results show an high ability of the system in the timely detection of events with magnitude equal or greater than 3.5 Richter with only 10\% of False Positives.},
  eventtitle = {2014 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communication Workshops}} ({{PERCOM WORKSHOPS}})},
  file = {/Users/mark/Zotero/storage/69TW2S9K/Avvenuti et al. - 2014 - Earthquake emergency management by social sensing.pdf;/Users/mark/Zotero/storage/H37W25CD/Avvenuti et al. - 2014 - Earthquake emergency management by social sensing.pdf},
  isbn = {978-1-4799-2736-4},
  langid = {english}
}

@article{bertUniversityPaderborn2019,
  title = {1 {{University}} of {{Paderborn}}},
  author = {Bert, Upb},
  date = {2019},
  pages = {10},
  file = {/Users/mark/Zotero/storage/73V9XBFV/Bert - 1 University of Paderborn.pdf},
  langid = {english}
}

@article{brynielssonInformingCrisisAlerts2018,
  ids = {brynielssonInformingCrisisAlerts},
  title = {Informing Crisis Alerts Using Social Media: {{Best}} Practices and Proof of Concept},
  shorttitle = {Informing Crisis Alerts Using Social Media},
  author = {Brynielsson, Joel and GranÃ¥sen, Magdalena and Lindquist, Sinna and Narganes Quijano, Maribel and Nilsson, Susanna and Trnka, Jiri},
  date = {2018-03},
  journaltitle = {Journal of Contingencies and Crisis Management},
  shortjournal = {J Contingencies Crisis Man},
  volume = {26},
  pages = {28--40},
  issn = {09660879},
  doi = {10.1111/1468-5973.12195},
  url = {http://doi.wiley.com/10.1111/1468-5973.12195},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/2QW2JLN3/Brynielsson et al. - Informing crisis alerts using social media Best p.pdf;/Users/mark/Zotero/storage/D9ZWXP8R/Brynielsson et al. - 2018 - Informing crisis alerts using social media Best p.pdf},
  langid = {english},
  number = {1}
}

@article{burelSemanticsDeepLearning2017,
  ids = {burelSemanticsDeepLearninga},
  title = {On {{Semantics}} and {{Deep Learning}} for {{Event Detection}} in {{Crisis Situations}}},
  author = {Burel, Gregoire and Saif, Hassan and Fernandez, Miriam and Alani, Harith},
  date = {2017},
  pages = {13},
  abstract = {In this paper, we introduce Dual-CNN, a semantically-enhanced deep learning model to target the problem of event detection in crisis situations from social media data. A layer of semantics is added to a traditional Convolutional Neural Network (CNN) model to capture the contextual information that is generally scarce in short, ill-formed social media messages. Our results show that our methods are able to successfully identify the existence of events, and event types (hurricane, floods, etc.) accurately ({$>$} 79\% F-measure), but the performance of the model significantly drops (61\% F-measure) when identifying fine-grained event-related information (affected individuals, damaged infrastructures, etc.). These results are competitive with more traditional Machine Learning models, such as SVM.},
  file = {/Users/mark/Zotero/storage/MR5DEIRG/Burel et al. - On Semantics and Deep Learning for Event Detection.pdf;/Users/mark/Zotero/storage/NRSR85E7/Burel et al. - On Semantics and Deep Learning for Event Detection.pdf},
  langid = {english}
}

@article{DataMiningUK2016,
  title = {Data {{Mining During UK Floods}}},
  date = {2016},
  file = {/Users/mark/Zotero/storage/LILVWHUR/spielhofer2016.pdf}
}

@thesis{EVENTTRACKERSOCIAL2019,
  title = {{{EVENT TRACKER}}: {{A SOCIAL MEDIA ANALYTICS PLATFORM FOR USE DURING DISASTERS}}},
  date = {2019},
  file = {/Users/mark/Zotero/storage/23ZQURX7/fame_2019_4.pdf}
}

@article{fanHybridMachineLearning2020,
  ids = {fanHybridMachineLearning2020a},
  title = {A {{Hybrid Machine Learning Pipeline}} for {{Automated Mapping}} of {{Events}} and {{Locations From Social Media}} in {{Disasters}}},
  author = {Fan, Chao and Wu, Fangsheng and Mostafavi, Ali},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {10478--10490},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2965550},
  url = {https://ieeexplore.ieee.org/document/8955890/},
  urldate = {2021-02-09},
  abstract = {The objective of this study is to propose and test a hybrid machine learning pipeline to uncover the unfolding of disaster events corresponding to different locations from social media posts during disasters. Effective disaster response and recovery require a comprehensive understanding of disaster situations, i.e., unfolding of disaster events and geographic distribution of the disruptions. Existing studies have employed machine learning methods to conduct coarse-grained event detection and analyze the geographical location information from geotagged social media data. However, only a very small fraction of the entire set of social media data includes geotagged information, which may not directly correspond to events described in the content of posts. In addition, the coarse-grained information detected by existing approaches is token-based, which does not provide sufficient information for situation awareness. Hence, the detection of location and finer-grained event information could significantly improve the utility, credibility, and interpretability of social media data for situation awareness. To address these limitations, this study proposed a hybrid machine learning pipeline that makes use of all relevant tweets to uncover the evolution of disaster events across different locations. The pipeline integrates Named Entity Recognition for detecting locations mentioned in the posts, location fusion approach to extract coordinates of the locations and remove noise information, finetuned BERT model for classifying posts with humanitarian categories, and graph-based clustering to identify credible situational information. The application of the study is demonstrated using the data set collected from Twitter during the 2017 Hurricane Harvey in Houston. The results show the capability of the proposed hybrid pipeline for automated mapping of events across time and space from social media posts with considerable accuracy. The findings also suggest that the potential for forensic analysis of disasters using mapped events and their evolution, and based on the variation of social media attention to different locations in disasters. Hence, this method could provide a useful tool to support emergency managers, public officials, residents, first responders, and other stakeholders in rapid situation awareness across time and space.},
  file = {/Users/mark/Zotero/storage/NZ76C2TZ/Fan et al. - 2020 - A Hybrid Machine Learning Pipeline for Automated M.pdf;/Users/mark/Zotero/storage/QGNW5GUN/Fan et al. - 2020 - A Hybrid Machine Learning Pipeline for Automated M.pdf},
  langid = {english}
}

@book{gelbukhComputationalLinguisticsIntelligent2015,
  title = {Computational Linguistics and Intelligent Text Processing: 16th International Conference, {{CICLing}} 2015, {{Cairo}}, {{Egypt}}, {{April}} 14-20, 2015. {{Pt}}. 2: ...},
  shorttitle = {Computational Linguistics and Intelligent Text Processing},
  editor = {Gelbukh, Alexander and CICLing},
  date = {2015},
  publisher = {{Springer}},
  location = {{Cham}},
  annotation = {OCLC: 931921181},
  eventtitle = {Annual {{Conference}} on {{Intelligent Text Processing}} and {{Computational Linguistics}}},
  file = {/Users/mark/Zotero/storage/GJGH6XLR/Gelbukh and CICLing - 2015 - Computational linguistics and intelligent text pro.pdf},
  isbn = {978-3-319-18117-2 978-3-319-18116-5},
  langid = {english},
  number = {9042},
  pagetotal = {686},
  series = {Lecture Notes in Computer Science {{Theoretical}} Computer Science and General Issues}
}

@article{ghoshExploitationSocialMedia2018,
  ids = {ghoshExploitationSocialMedia2018a},
  title = {Exploitation of {{Social Media}} for {{Emergency Relief}} and {{Preparedness}}: {{Recent Research}} and {{Trends}}},
  shorttitle = {Exploitation of {{Social Media}} for {{Emergency Relief}} and {{Preparedness}}},
  author = {Ghosh, Saptarshi and Ghosh, Kripabandhu and Ganguly, Debasis and Chakraborty, Tanmoy and Jones, Gareth J. F. and Moens, Marie-Francine and Imran, Muhammad},
  date = {2018-10},
  journaltitle = {Information Systems Frontiers},
  shortjournal = {Inf Syst Front},
  volume = {20},
  pages = {901--907},
  issn = {1387-3326, 1572-9419},
  doi = {10.1007/s10796-018-9878-z},
  url = {http://link.springer.com/10.1007/s10796-018-9878-z},
  urldate = {2021-02-09},
  abstract = {Online Social Media, such as Twitter, Facebook and WhatsApp, are important sources of real-time information related to emergency events, including both natural calamities, man-made disasters, epidemics, and so on. There has been lot of recent work on designing information systems that would be useful for aiding post-disaster relief operations, as well as for pre-disaster preparedness. A special issue on BExploitation of Social Media for Emergency Relief and Preparedness\^ was conducted for the journal Information Systems Frontiers. The objective of this special issue was to present a platform for dissemination of the empirical results of various technologies for extracting vital and actionable information from social media content in disaster situations. The papers included in this issue are expected to be the stepping stones for future explorations and technical innovations towards technologies meant for utilizing various online and offline information sources for enhancing pre-disaster preparedness and post-disaster relief operations.},
  file = {/Users/mark/Zotero/storage/PLDH84AS/Ghosh et al. - 2018 - Exploitation of Social Media for Emergency Relief .pdf;/Users/mark/Zotero/storage/RSFMQN42/Ghosh et al. - 2018 - Exploitation of Social Media for Emergency Relief .pdf},
  langid = {english},
  number = {5}
}

@report{gimpelPartofSpeechTaggingTwitter2010,
  title = {Part-of-{{Speech Tagging}} for {{Twitter}}: {{Annotation}}, {{Features}}, and {{Experiments}}:},
  shorttitle = {Part-of-{{Speech Tagging}} for {{Twitter}}},
  author = {Gimpel, Kevin and Schneider, Nathan and O'Connor, Brendan and Das, Dipanjan and Mills, Daniel and Eisenstein, Jacob and Heilman, Michael and Yogatama, Dani and Flanigan, Jeffrey and Smith, Noah A.},
  date = {2010-01-01},
  institution = {{Defense Technical Information Center}},
  location = {{Fort Belvoir, VA}},
  doi = {10.21236/ADA547371},
  url = {http://www.dtic.mil/docs/citations/ADA547371},
  urldate = {2021-02-09},
  abstract = {We address the problem of part-of-speech tagging for English data from the popular microblogging service Twitter. We develop a tagset, annotate data, develop features, and report tagging results nearing 90\% accuracy. The data and tools have been made available to the research community with the goal of enabling richer text analysis of Twitter and related social media data sets.},
  file = {/Users/mark/Zotero/storage/NCDS7KRX/Gimpel et al. - 2010 - Part-of-Speech Tagging for Twitter Annotation, Fe.pdf},
  langid = {english}
}

@inproceedings{godinUsingTopicModels2013,
  title = {Using Topic Models for {{Twitter}} Hashtag Recommendation},
  booktitle = {Proceedings of the 22nd {{International Conference}} on {{World Wide Web}} - {{WWW}} '13 {{Companion}}},
  author = {Godin, FrÃ©deric and Slavkovikj, Viktor and De Neve, Wesley and Schrauwen, Benjamin and Van de Walle, Rik},
  date = {2013},
  pages = {593--596},
  publisher = {{ACM Press}},
  location = {{Rio de Janeiro, Brazil}},
  doi = {10.1145/2487788.2488002},
  url = {http://dl.acm.org/citation.cfm?doid=2487788.2488002},
  urldate = {2021-02-09},
  abstract = {Since the introduction of microblogging services, there has been a continuous growth of short-text social networking on the Internet. With the generation of large amounts of microposts, there is a need for effective categorization and search of the data. Twitter, one of the largest microblogging sites, allows users to make use of hashtags to categorize their posts. However, the majority of tweets do not contain tags, which hinders the quality of the search results. In this paper, we propose a novel method for unsupervised and contentbased hashtag recommendation for tweets. Our approach relies on Latent Dirichlet Allocation (LDA) to model the underlying topic assignment of language classified tweets. The advantage of our approach is the use of a topic distribution to recommend general hashtags.},
  eventtitle = {The 22nd {{International Conference}}},
  file = {/Users/mark/Zotero/storage/WC47HYIH/Godin et al. - 2013 - Using topic models for Twitter hashtag recommendat.pdf},
  isbn = {978-1-4503-2038-2},
  langid = {english}
}

@article{grahamGuideSocialMedia2015,
  ids = {grahamGuideSocialMediaa},
  title = {A Guide to Social Media Emergency Management Analytics: {{Understanding}} Its Place through {{Typhoon Haiyan}} Tweets},
  author = {Graham, Cat and Thompson, Chris and Wolcott, Michiko and Pollack, Joseph and Tran, Minh},
  date = {2015},
  pages = {10},
  abstract = {Social media can play a critical role in the dissemination of the information as well as collection of relevant data during natural disasters. The idea of leveraging social media data such as Twitter is intuitively attractive, given their natural ties to mobile devices with obvious disaster response implications.},
  file = {/Users/mark/Zotero/storage/8PHLE7DE/Graham et al. - A guide to social media emergency management analy.pdf;/Users/mark/Zotero/storage/HXFF79MU/Graham et al. - A guide to social media emergency management analy.pdf},
  langid = {english}
}

@thesis{HierarchicalEventDetection2015,
  title = {Hierarchical {{Event Detection}} and {{Clustering}} in {{Micro}}-{{Blogs}} Using {{Topic Models}}},
  date = {2015},
  file = {/Users/mark/Zotero/storage/QE4LHDJS/report.pdf}
}

@misc{InnovativeUsesSocial2013,
  ids = {InnovativeUsesSociala},
  title = {Innovative {{Uses}} of {{Social Media}} in {{Emergency Management}}},
  date = {2013},
  file = {/Users/mark/Zotero/storage/RBBRMHNS/Innovative Uses of Social Media in Emergency Manag.pdf;/Users/mark/Zotero/storage/WC342VFM/Innovative Uses of Social Media in Emergency Manag.pdf},
  langid = {english}
}

@article{kabakusTwitterSentiDetectorDomainindependentTwitter2018,
  ids = {kabakusTwitterSentiDetectorDomainindependentTwitter2018a},
  title = {{{TwitterSentiDetector}}: A Domain-Independent {{Twitter}} Sentiment Analyser},
  shorttitle = {{{TwitterSentiDetector}}},
  author = {Kabakus, Abdullah Talha and Kara, Resul},
  date = {2018-04-03},
  journaltitle = {INFOR: Information Systems and Operational Research},
  shortjournal = {INFOR: Information Systems and Operational Research},
  volume = {56},
  pages = {137--162},
  issn = {0315-5986, 1916-0615},
  doi = {10.1080/03155986.2017.1340797},
  url = {https://www.tandfonline.com/doi/full/10.1080/03155986.2017.1340797},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/LFZESJST/Kabakus and Kara - 2018 - TwitterSentiDetector a domain-independent Twitter.pdf;/Users/mark/Zotero/storage/LJITGEBR/Kabakus and Kara - 2018 - TwitterSentiDetector a domain-independent Twitter.pdf},
  langid = {english},
  number = {2}
}

@article{kerstenWhatHappensWhere2020,
  title = {What Happens Where during Disasters? {{A Workflow}} for the Multifaceted Characterization of Crisis Events Based on {{Twitter}} Data},
  shorttitle = {What Happens Where during Disasters?},
  author = {Kersten, Jens and Klan, Friederike},
  date = {2020-09},
  journaltitle = {Journal of Contingencies and Crisis Management},
  shortjournal = {J Contingencies and Crisis Management},
  volume = {28},
  pages = {262--280},
  issn = {0966-0879, 1468-5973},
  doi = {10.1111/1468-5973.12321},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1468-5973.12321},
  urldate = {2021-02-09},
  abstract = {Twitter data are a valuable source of information for rescue and helping activities in case of natural disasters and technical accidents. Several methods for disaster- and event-related tweet filtering and classification are available to analyse social media streams. Rather than processing single tweets, taking into account space and time is likely to reveal even more insights regarding local event dynamics and impacts on population and environment. This study focuses on the design and evaluation of a generic workflow for Twitter data analysis that leverages that additional information to characterize crisis events more comprehensively. The workflow covers data acquisition, analysis and visualization, and aims at the provision of a multifaceted and detailed picture of events that happen in affected areas. This is approached by utilizing agile and flexible analysis methods providing different and complementary views on the data. Utilizing state-of-the-art deep learning and clustering methods, we are interested in the question, whether our workflow is suitable to reconstruct and picture the course of events during major natural disasters from Twitter data. Experimental results obtained with a data set acquired during hurricane Florence in September 2018 demonstrate the effectiveness of the applied methods but also indicate further interesting research questions and directions.},
  file = {/Users/mark/Zotero/storage/NGGINKLN/Kersten and Klan - 2020 - What happens where during disasters A Workflow fo.pdf},
  langid = {english},
  number = {3}
}

@inproceedings{kongDependencyParserTweets2014,
  title = {A {{Dependency Parser}} for {{Tweets}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Kong, Lingpeng and Schneider, Nathan and Swayamdipta, Swabha and Bhatia, Archna and Dyer, Chris and Smith, Noah A.},
  date = {2014},
  pages = {1001--1012},
  publisher = {{Association for Computational Linguistics}},
  location = {{Doha, Qatar}},
  doi = {10.3115/v1/D14-1108},
  url = {http://aclweb.org/anthology/D14-1108},
  urldate = {2021-02-09},
  abstract = {We describe a new dependency parser for English tweets, TWEEBOPARSER. The parser builds on several contributions: new syntactic annotations for a corpus of tweets (TWEEBANK), with conventions informed by the domain; adaptations to a statistical parsing algorithm; and a new approach to exploiting out-of-domain Penn Treebank data. Our experiments show that the parser achieves over 80\% unlabeled attachment accuracy on our new, high-quality test set and measure the benefit of our contributions. Our dataset and parser can be found at http://www.ark.cs.cmu.edu/TweetNLP.},
  eventtitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  file = {/Users/mark/Zotero/storage/PB5NNGZM/Kong et al. - 2014 - A Dependency Parser for Tweets.pdf},
  langid = {english}
}

@article{margineantuMachineLearningAlgorithms2010,
  ids = {margineantuMachineLearningAlgorithms2010a},
  title = {Machine Learning Algorithms for Event Detection: {{A}} Special Issue of {{Machine Learning}}},
  shorttitle = {Machine Learning Algorithms for Event Detection},
  author = {Margineantu, Dragos and Wong, Weng-Keen and Dash, Denver},
  date = {2010-06},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {79},
  pages = {257--259},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-010-5184-9},
  url = {http://link.springer.com/10.1007/s10994-010-5184-9},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/DNHXHKLN/Margineantu et al. - 2010 - Machine learning algorithms for event detection A.pdf;/Users/mark/Zotero/storage/X6W997DY/Margineantu et al. - 2010 - Machine learning algorithms for event detection A.pdf},
  langid = {english},
  number = {3}
}

@thesis{mazziaSuggestingHashtagsTwitter2010,
  title = {Suggesting {{Hashtags}} on {{Twitter}}},
  author = {Mazzia, Allie and Juett, James},
  date = {2010},
  abstract = {As micro-blogging sites, like Twitter, continue to grow in popularity, we are presented with the problem of how to effectively categorize and search for posts. Looking specifically at Twitter, we see that users may categorize their posts using hashtags, and any word or phrase may be used as the category. Attempting to search for tweets about Facebook, a user would need to try many different hashtags, like \#Facebook, \#FB, \#Facebook.com, or \#Zuckerberg. To combat this, we propose, implement and evaluate a tool for suggesting relevant hashtags to a user, given a tweet. Initial analyses suggest our dataset is rich enough to extract informative distributions of words for many hashtags that will facilitate a naive Bayes model for hashtag recommendation given a query post.},
  file = {/Users/mark/Zotero/storage/I5AVKVUY/Mazzia and Juett - Suggesting Hashtags on Twitter.pdf},
  langid = {english}
}

@article{mccreadieIncidentStreams20192019,
  title = {Incident {{Streams}} 2019: {{Actionable Insights}} and {{How}} to {{Find Them}}},
  author = {McCreadie, Richard and Buntain, Cody and Soboroff, Ian},
  date = {2019},
  pages = {17},
  abstract = {The ubiquity of mobile internet-enabled devices combined with wide-spread social media use during emergencies is posing new challenges for response personnel. In particular, service operators are now expected to monitor these online channels to extract actionable insights and answer questions from the public. A lack of adequate tools makes this monitoring impractical at the scale of many emergencies. The TREC Incident Streams (TREC-IS) track drives research into solving this technology gap by bringing together academia and industry to develop techniques for extracting actionable insights from social media streams during emergencies. This paper covers the second year of TREC-IS, hosted in 2019 with two editions, 2019-A and 2019-B, contributing 12 new events and approximately 20,000 new tweets across 25 information categories, with 15 research groups participating across the world. This paper provides an overview of these new editions, actionable insights from data labelling, and the automated techniques employed by participant systems that appear most effective.},
  file = {/Users/mark/Zotero/storage/ERZ5KZST/McCreadie et al. - 2019 - Incident Streams 2019 Actionable Insights and How.pdf},
  langid = {english}
}

@inproceedings{mccreadieScalableDistributedEvent2013,
  ids = {mccreadieScalableDistributedEvent2013a},
  title = {Scalable Distributed Event Detection for {{Twitter}}},
  booktitle = {2013 {{IEEE International Conference}} on {{Big Data}}},
  author = {McCreadie, Richard and Macdonald, Craig and Ounis, Iadh and Osborne, Miles and Petrovic, Sasa},
  date = {2013-10},
  pages = {543--549},
  publisher = {{IEEE}},
  location = {{Silicon Valley, CA, USA}},
  doi = {10.1109/BigData.2013.6691620},
  url = {http://ieeexplore.ieee.org/document/6691620/},
  urldate = {2021-02-09},
  abstract = {Social media streams, such as Twitter, have shown themselves to be useful sources of real-time information about what is happening in the world. Automatic detection and tracking of events identified in these streams have a variety of real-world applications, e.g. identifying and automatically reporting road accidents for emergency services. However, to be useful, events need to be identified within the stream with a very low latency. This is challenging due to the high volume of posts within these social streams. In this paper, we propose a novel event detection approach that can both effectively detect events within social streams like Twitter and can scale to thousands of posts every second. Through experimentation on a large Twitter dataset, we show that our approach can process the equivalent to the full Twitter Firehose stream, while maintaining event detection accuracy and outperforming an alternative distributed event detection system.},
  eventtitle = {2013 {{IEEE International Conference}} on {{Big Data}}},
  file = {/Users/mark/Zotero/storage/C999AI33/McCreadie et al. - 2013 - Scalable distributed event detection for Twitter.pdf;/Users/mark/Zotero/storage/NTSRMNVI/McCreadie et al. - 2013 - Scalable distributed event detection for Twitter.pdf},
  isbn = {978-1-4799-1293-3},
  langid = {english}
}

@article{mccreadieTRECIncidentStreams2019,
  ids = {mccreadieTRECIncidentStreams2019a,mccreadieTRECIncidentStreams2019b,mccreadieTRECIncidentStreams2019c},
  title = {{{TREC Incident Streams}}: {{Finding Actionable Information}} on {{Social Media}}},
  author = {McCreadie, Richard and Buntain, Cody and Soboroff, Ian},
  date = {2019},
  pages = {15},
  abstract = {The Text Retrieval Conference (TREC) Incident Streams track is a new initiative that aims to mature social media-based emergency response technology. This initiative advances the state of the art in this area through an evaluation challenge, which attracts researchers and developers from across the globe. The 2018 edition of the track provides a standardized evaluation methodology, an ontology of emergency-relevant social media information types, proposes a scale for information criticality, and releases a dataset containing fifteen test events and approximately 20,000 labeled tweets. Analysis of this dataset reveals a significant amount of actionable information on social media during emergencies ({$>$} 10\%). While this data is valuable for emergency response efforts, analysis of the 39 state-of-the-art systems demonstrate a performance gap in identifying this data. We therefore find the current state-of-the-art is insufficient for emergency respondersâ requirements, particularly for rare actionable information for which there is little prior training data available.},
  file = {/Users/mark/Zotero/storage/J7MCIHU6/McCreadie et al. - 2019 - TREC Incident Streams Finding Actionable Informat.pdf;/Users/mark/Zotero/storage/PMYRPX8D/McCreadie et al. - 2019 - TREC Incident Streams Finding Actionable Informat.pdf;/Users/mark/Zotero/storage/RXBV8R5P/McCreadie et al. - 2019 - TREC Incident Streams Finding Actionable Informat.pdf;/Users/mark/Zotero/storage/VFVFVUNW/McCreadie et al. - 2019 - TREC Incident Streams Finding Actionable Informat.pdf},
  langid = {english}
}

@inproceedings{mcminnBuildingLargescaleCorpus2013,
  title = {Building a Large-Scale Corpus for Evaluating Event Detection on Twitter},
  booktitle = {Proceedings of the 22nd {{ACM}} International Conference on {{Conference}} on Information \& Knowledge Management - {{CIKM}} '13},
  author = {McMinn, Andrew J. and Moshfeghi, Yashar and Jose, Joemon M.},
  date = {2013},
  pages = {409--418},
  publisher = {{ACM Press}},
  location = {{San Francisco, California, USA}},
  doi = {10.1145/2505515.2505695},
  url = {http://dl.acm.org/citation.cfm?doid=2505515.2505695},
  urldate = {2021-02-09},
  abstract = {Despite the popularity of Twitter for research, there are very few publicly available corpora, and those which are available are either too small or unsuitable for tasks such as event detection. This is partially due to a number of issues associated with the creation of Twitter corpora, including restrictions on the distribution of the tweets and the difficultly of creating relevance judgements at such a large scale. The difficulty of creating relevance judgements for the task of event detection is further hampered by ambiguity in the definition of event. In this paper, we propose a methodology for the creation of an event detection corpus. Specifically, we first create a new corpus that covers a period of 4 weeks and contains over 120 million tweets, which we make available for research. We then propose a definition of event which fits the characteristics of Twitter, and using this definition, we generate a set of relevance judgements aimed specifically at the task of event detection. To do so, we make use of existing state-of-the-art event detection approaches and Wikipedia to generate a set of candidate events with associated tweets. We then use crowdsourcing to gather relevance judgements, and discuss the quality of results, including how we ensured integrity and prevented spam. As a result of this process, along with our Twitter corpus, we release relevance judgements containing over 150,000 tweets, covering more than 500 events, which can be used for the evaluation of event detection approaches.},
  eventtitle = {The 22nd {{ACM}} International Conference},
  file = {/Users/mark/Zotero/storage/QUUJ9TK5/McMinn et al. - 2013 - Building a large-scale corpus for evaluating event.pdf},
  isbn = {978-1-4503-2263-8},
  langid = {english}
}

@inproceedings{mehrotraImprovingLDATopic2013,
  title = {Improving {{LDA}} Topic Models for Microblogs via Tweet Pooling and Automatic Labeling},
  booktitle = {Proceedings of the 36th International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Mehrotra, Rishabh and Sanner, Scott and Buntine, Wray and Xie, Lexing},
  date = {2013-07-28},
  pages = {889--892},
  publisher = {{ACM}},
  location = {{Dublin Ireland}},
  doi = {10.1145/2484028.2484166},
  url = {https://dl.acm.org/doi/10.1145/2484028.2484166},
  urldate = {2021-02-09},
  abstract = {Twitter, or the world of 140 characters poses serious challenges to the efficacy of topic models on short, messy text. While topic models such as Latent Dirichlet Allocation (LDA) have a long history of successful application to news articles and academic abstracts, they are often less coherent when applied to microblog content like Twitter. In this paper, we investigate methods to improve topics learned from Twitter content without modifying the basic machinery of LDA; we achieve this through various pooling schemes that aggregate tweets in a data preprocessing step for LDA. We empirically establish that a novel method of tweet pooling by hashtags leads to a vast improvement in a variety of measures for topic coherence across three diverse Twitter datasets in comparison to an unmodified LDA baseline and a variety of pooling schemes. An additional contribution of automatic hashtag labeling further improves on the hashtag pooling results for a subset of metrics. Overall, these two novel schemes lead to significantly improved LDA topic models on Twitter content.},
  eventtitle = {{{SIGIR}} '13: {{The}} 36th {{International ACM SIGIR}} Conference on Research and Development in {{Information Retrieval}}},
  file = {/Users/mark/Zotero/storage/MT7MH6A7/Mehrotra et al. - 2013 - Improving LDA topic models for microblogs via twee.pdf},
  isbn = {978-1-4503-2034-4},
  langid = {english}
}

@inproceedings{miyazakiLabelEmbeddingUsing2019,
  ids = {miyazakiLabelEmbeddingUsing2019a},
  title = {Label {{Embedding}} Using {{Hierarchical Structure}} of {{Labels}} for {{Twitter Classification}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP}}-{{IJCNLP}})},
  author = {Miyazaki, Taro and Makino, Kiminobu and Takei, Yuka and Okamoto, Hiroki and Goto, Jun},
  date = {2019},
  pages = {6316--6321},
  publisher = {{Association for Computational Linguistics}},
  location = {{Hong Kong, China}},
  doi = {10.18653/v1/D19-1660},
  url = {https://www.aclweb.org/anthology/D19-1660},
  urldate = {2021-02-09},
  abstract = {Twitter is used for various applications such as disaster monitoring and news material gathering. In these applications, each Tweet is classified into pre-defined classes. These classes have a semantic relationship with each other and can be classified into a hierarchical structure, which is regarded as important information. Label texts of pre-defined classes themselves also include important clues for classification. Therefore, we propose a method that can consider the hierarchical structure of labels and label texts themselves. We conducted evaluation over the Text REtrieval Conference (TREC) 2018 Incident Streams (IS) track dataset, and we found that our method outperformed the methods of the conference participants.},
  eventtitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP}}-{{IJCNLP}})},
  file = {/Users/mark/Zotero/storage/GIK8GUCD/Miyazaki et al. - 2019 - Label Embedding using Hierarchical Structure of La.pdf;/Users/mark/Zotero/storage/UUTYHYDB/Miyazaki et al. - 2019 - Label Embedding using Hierarchical Structure of La.pdf},
  langid = {english}
}

@report{owoputiImprovedPartofSpeechTagging2013,
  title = {Improved {{Part}}-of-{{Speech Tagging}} for {{Online Conversational Text}} with {{Word Clusters}}},
  author = {Owoputi, Olutobi and OâConnor, Brendan and Dyer, Chris and Gimpel, Kevin and Schneider, Nathan and Smith, Noah A},
  date = {2013},
  pages = {11},
  abstract = {We consider the problem of part-of-speech tagging for informal, online conversational text. We systematically evaluate the use of large-scale unsupervised word clustering and new lexical features to improve tagging accuracy. With these features, our system achieves state-of-the-art tagging results on both Twitter and IRC POS tagging tasks; Twitter tagging is improved from 90\% to 93\% accuracy (more than 3\% absolute). Qualitative analysis of these word clusters yields insights about NLP and linguistic phenomena in this genre. Additionally, we contribute the first POS annotation guidelines for such text and release a new dataset of English language tweets annotated using these guidelines. Tagging software, annotation guidelines, and large-scale word clusters are available at: http://www.ark.cs.cmu.edu/TweetNLP This paper describes release 0.3 of the âCMU Twitter Part-of-Speech Taggerâ and annotated data.},
  file = {/Users/mark/Zotero/storage/DJ3PZSYI/Owoputi et al. - Improved Part-of-Speech Tagging for Online Convers.pdf},
  langid = {english}
}

@article{panemMasterScienceResearch2015,
  ids = {panemMasterScienceResearcha},
  title = {Master of {{Science}} (by {{Research}}) in {{Computer Science}} and {{Engineering}}},
  author = {Panem, Sandeep},
  date = {2015},
  pages = {79},
  file = {/Users/mark/Zotero/storage/QL9BLYZN/Panem - Master of Science (by Research) in Computer Scienc.pdf;/Users/mark/Zotero/storage/SYQGDVKV/Panem - Master of Science (by Research) in Computer Scienc.pdf},
  langid = {english}
}

@article{pintoComparingPerformanceDifferent2016,
  title = {Comparing the {{Performance}} of {{Different NLP Toolkits}} in {{Formal}} and {{Social Media Text}}},
  author = {Pinto, Alexandre and GonÃ§alo Oliveira, Hugo and Oliveira Alves, Ana},
  date = {2016},
  pages = {16 pages},
  publisher = {{Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany}},
  doi = {10.4230/OASICS.SLATE.2016.3},
  url = {http://drops.dagstuhl.de/opus/volltexte/2016/6008/},
  urldate = {2021-02-09},
  abstract = {Nowadays, there are many toolkits available for performing common natural language processing tasks, which enable the development of more powerful applications without having to start from scratch. In fact, for English, there is no need to develop tools such as tokenizers, partof-speech (POS) taggers, chunkers or named entity recognizers (NER). The current challenge is to select which one to use, out of the range of available tools. This choice may depend on several aspects, including the kind and source of text, where the level, formal or informal, may influence the performance of such tools. In this paper, we assess a range of natural language processing toolkits with their default configuration, while performing a set of standard tasks (e.g. tokenization, POS tagging, chunking and NER), in popular datasets that cover newspaper and social network text. The obtained results are analyzed and, while we could not decide on a single toolkit, this exercise was very helpful to narrow our choice.},
  editora = {Herbstritt, Marc},
  editoratype = {collaborator},
  file = {/Users/mark/Zotero/storage/SU4B25FV/Pinto et al. - 2016 - Comparing the Performance of Different NLP Toolkit.pdf},
  keywords = {000 Computer science; knowledge; general works,Computer Science},
  langid = {english}
}

@inproceedings{pohlAutomaticSubeventDetection2012,
  ids = {pohlAutomaticSubeventDetection2012a},
  title = {Automatic Sub-Event Detection in Emergency Management Using Social Media},
  booktitle = {Proceedings of the 21st International Conference Companion on {{World Wide Web}} - {{WWW}} '12 {{Companion}}},
  author = {Pohl, Daniela and Bouchachia, Abdelhamid and Hellwagner, Hermann},
  date = {2012},
  pages = {683},
  publisher = {{ACM Press}},
  location = {{Lyon, France}},
  doi = {10.1145/2187980.2188180},
  url = {http://dl.acm.org/citation.cfm?doid=2187980.2188180},
  urldate = {2021-02-09},
  abstract = {Emergency management is about assessing critical situations, followed by decision making as a key step. Clearly, information is crucial in this two-step process. The technology of social (multi)media turns out to be an interesting source for collecting information about an emergency situation. In particular, situational information can be captured in form of pictures, videos, or text messages. The present paper investigates the application of multimedia metadata to identify the set of sub-events related to an emergency situation. The used metadata is compiled from Flickr and YouTube during an emergency situation, where the identification of the events relies on clustering. Initial results presented in this paper show how social media data can be used to detect different sub-events in a critical situation.},
  eventtitle = {The 21st International Conference Companion},
  file = {/Users/mark/Zotero/storage/DPDXALEH/Pohl et al. - 2012 - Automatic sub-event detection in emergency managem.pdf;/Users/mark/Zotero/storage/MPUIDFAW/Pohl et al. - 2012 - Automatic sub-event detection in emergency managem.pdf},
  isbn = {978-1-4503-1230-1},
  langid = {english}
}

@article{pohlOnlineIndexingClustering2016,
  ids = {pohlOnlineIndexingClustering2016a},
  title = {Online Indexing and Clustering of Social Media Data for Emergency Management},
  author = {Pohl, Daniela and Bouchachia, Abdelhamid and Hellwagner, Hermann},
  date = {2016-01},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {172},
  pages = {168--179},
  issn = {09252312},
  doi = {10.1016/j.neucom.2015.01.084},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S092523121500613X},
  urldate = {2021-02-09},
  abstract = {Social media becomes a vital part in our daily communication practice, creating a huge amount of data and covering different real-world situations. Currently, there is a tendency in making use of social media during emergency management and response. Most of this effort is performed by a huge number of volunteers browsing through social media data and preparing maps that can be used by professional first responders. Automatic analysis approaches are needed to directly support the response teams in monitoring and also understanding the evolution of facts in social media during an emergency situation. In this paper, we investigate the problem of real-time sub-events identification in social media data (i.e., Twitter, Flickr and YouTube) during emergencies. A processing framework is presented serving to generate situational reports/summaries from social media data. This framework relies in particular on online indexing and online clustering of media data streams. Online indexing aims at tracking the relevant vocabulary to capture the evolution of sub-events over time. Online clustering, on the other hand, is used to detect and update the set of sub-events using the indices built during online indexing. To evaluate the framework, social media data related to Hurricane Sandy 2012 was collected and used in a series of experiments. In particular some online indexing methods have been tested against a proposed method to show their suitability. Moreover, the quality of online clustering has been studied using standard clustering indices. Overall the framework provides a great opportunity for supporting emergency responders as demonstrated in real-world emergency exercises.},
  file = {/Users/mark/Zotero/storage/57TNCEL4/Pohl et al. - 2016 - Online indexing and clustering of social media dat.pdf;/Users/mark/Zotero/storage/LP2SHLYJ/Pohl et al. - 2016 - Online indexing and clustering of social media dat.pdf},
  langid = {english}
}

@inproceedings{ramageLabeledLDASupervised2009,
  title = {Labeled {{LDA}}: A Supervised Topic Model for Credit Attribution in Multi-Labeled Corpora},
  shorttitle = {Labeled {{LDA}}},
  booktitle = {Proceedings of the 2009 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing Volume}} 1 - {{EMNLP}} '09},
  author = {Ramage, Daniel and Hall, David and Nallapati, Ramesh and Manning, Christopher D.},
  date = {2009},
  volume = {1},
  pages = {248},
  publisher = {{Association for Computational Linguistics}},
  location = {{Singapore}},
  doi = {10.3115/1699510.1699543},
  url = {http://portal.acm.org/citation.cfm?doid=1699510.1699543},
  urldate = {2021-02-09},
  abstract = {A significant portion of the worldâs text is tagged by readers on social bookmarking websites. Credit attribution is an inherent problem in these corpora because most pages have multiple tags, but the tags do not always apply with equal specificity across the whole document. Solving the credit attribution problem requires associating each word in a document with the most appropriate tags and vice versa. This paper introduces Labeled LDA, a topic model that constrains Latent Dirichlet Allocation by defining a one-to-one correspondence between LDAâs latent topics and user tags. This allows Labeled LDA to directly learn word-tag correspondences. We demonstrate Labeled LDAâs improved expressiveness over traditional LDA with visualizations of a corpus of tagged web pages from del.icio.us. Labeled LDA outperforms SVMs by more than 3 to 1 when extracting tag-specific document snippets. As a multi-label text classifier, our model is competitive with a discriminative baseline on a variety of datasets.},
  eventtitle = {The 2009 {{Conference}}},
  file = {/Users/mark/Zotero/storage/6QW8DRRR/Ramage et al. - 2009 - Labeled LDA a supervised topic model for credit a.pdf},
  isbn = {978-1-932432-59-6},
  langid = {english}
}

@article{reuterFifteenYearsSocial2018,
  ids = {reuterFifteenYearsSocial},
  title = {Fifteen Years of Social Media in Emergencies: {{A}} Retrospective Review and Future Directions for Crisis {{Informatics}}},
  shorttitle = {Fifteen Years of Social Media in Emergencies},
  author = {Reuter, Christian and Kaufhold, Marc-AndrÃ©},
  date = {2018-03},
  journaltitle = {Journal of Contingencies and Crisis Management},
  shortjournal = {J Contingencies Crisis Man},
  volume = {26},
  pages = {41--57},
  issn = {09660879},
  doi = {10.1111/1468-5973.12196},
  url = {http://doi.wiley.com/10.1111/1468-5973.12196},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/8P7WSXYU/Reuter - Fifteen years of social media in emergencies A re.pdf;/Users/mark/Zotero/storage/RWCKH8U6/Reuter and Kaufhold - 2018 - Fifteen years of social media in emergencies A re.pdf},
  langid = {english},
  number = {1}
}

@article{rexilineraginiMiningCrisisInformation2018,
  ids = {rexilineraginiMiningCrisisInformation2018a},
  title = {Mining Crisis Information: {{A}} Strategic Approach for Detection of People at Risk through Social Media Analysis},
  shorttitle = {Mining Crisis Information},
  author = {Rexiline Ragini, J. and Rubesh Anand, P.M. and Bhaskar, Vidhyacharan},
  date = {2018-03},
  journaltitle = {International Journal of Disaster Risk Reduction},
  shortjournal = {International Journal of Disaster Risk Reduction},
  volume = {27},
  pages = {556--566},
  issn = {22124209},
  doi = {10.1016/j.ijdrr.2017.12.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2212420917303485},
  urldate = {2021-02-09},
  abstract = {Situational awareness of the rapidly changing environment in the event of disaster is vital for effective response and recovery management. The major challenges in achieving such awareness are lack of access to various sources of information and tools. Social media plays a vital role in understanding the real situation at the place of disaster as the information is received directly from the affected people. If the collected information is leveraged effectively, the crisis situation can be brought under control and the risks of the disaster affected people or disaster prone areas are reduced. This indeed minimizes the casualty and helps the affected people in serving with their basic needs and medical emergencies. In this paper, we propose a hybrid method for segregating and classifying the texts1 received from the people who are at risk in the affected region. The proposed hybrid method combines rule based methodology and machine learning algorithms with linguistic features for segregating the texts and classifying them according to the needs. The results of the real-time text classification algorithm help the emergency responders to locate the people at risk and reach them during the hour of their need.},
  file = {/Users/mark/Zotero/storage/6N6AAGB7/Rexiline Ragini et al. - 2018 - Mining crisis information A strategic approach fo.pdf;/Users/mark/Zotero/storage/J5YJAPKL/Rexiline Ragini et al. - 2018 - Mining crisis information A strategic approach fo.pdf},
  langid = {english}
}

@article{saeedWhatHappeningWorld2019,
  ids = {saeedWhatHappeningWorld2019a},
  title = {Whatâs {{Happening Around}} the {{World}}? {{A Survey}} and {{Framework}} on {{Event Detection Techniques}} on {{Twitter}}},
  shorttitle = {Whatâs {{Happening Around}} the {{World}}?},
  author = {Saeed, Zafar and Abbasi, Rabeeh Ayaz and Maqbool, Onaiza and Sadaf, Abida and Razzak, Imran and Daud, Ali and Aljohani, Naif Radi and Xu, Guandong},
  date = {2019-06},
  journaltitle = {Journal of Grid Computing},
  shortjournal = {J Grid Computing},
  volume = {17},
  pages = {279--312},
  issn = {1570-7873, 1572-9184},
  doi = {10.1007/s10723-019-09482-2},
  url = {http://link.springer.com/10.1007/s10723-019-09482-2},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/5W4QTMZG/Saeed et al. - 2019 - Whatâs Happening Around the World A Survey and Fr.pdf;/Users/mark/Zotero/storage/NSWHFSYT/Saeed et al. - 2019 - Whatâs Happening Around the World A Survey and Fr.pdf;/Users/mark/Zotero/storage/R8LNS8Y7/Saeed et al. - 2019 - Whatâs Happening Around the World A Survey and Fr.pdf},
  langid = {english},
  number = {2}
}

@inproceedings{serraDemoPaperStamat2013,
  ids = {serraDemoPaperStamat2013a},
  title = {Demo Paper: {{Stamat}}: {{A}} Framework for {{Social Topics}} and {{Media Analysis}}},
  shorttitle = {Demo Paper},
  booktitle = {2013 {{IEEE International Conference}} on {{Multimedia}} and {{Expo Workshops}} ({{ICMEW}})},
  author = {Serra, Giuseppe and Alisi, Thomas and Bertini, Marco and Ballan, Lamberto and Del Bimbo, Alberto and Goix, Laurent Walter and Licciardi, Carlo Alberto},
  date = {2013-07},
  pages = {1--2},
  publisher = {{IEEE}},
  location = {{San Jose, CA, USA}},
  doi = {10.1109/ICMEW.2013.6618227},
  url = {http://ieeexplore.ieee.org/document/6618227/},
  urldate = {2021-02-09},
  abstract = {Analysis of trending topics in social networks, based both on textual and multimedia content, can be used by content providers to measure the buzz around their channels, and even to create new material based on the current memes propagating across Twitter, Google+, Facebook etc.},
  eventtitle = {2013 {{IEEE International Conference}} on {{Multimedia}} and {{Expo Workshops}} ({{ICMEW}})},
  file = {/Users/mark/Zotero/storage/4TR9KBTQ/Serra et al. - 2013 - Demo paper Stamat A framework for Social Topics .pdf;/Users/mark/Zotero/storage/YMEI7EDD/Serra et al. - 2013 - Demo paper Stamat A framework for Social Topics .pdf},
  isbn = {978-1-4799-1604-7},
  langid = {english}
}

@article{simonSocializingEmergenciesReview2015,
  ids = {simonSocializingEmergenciesReview2015a},
  title = {Socializing in Emergenciesâ{{A}} Review of the Use of Social Media in Emergency Situations},
  author = {Simon, Tomer and Goldberg, Avishay and Adini, Bruria},
  date = {2015-10},
  journaltitle = {International Journal of Information Management},
  shortjournal = {International Journal of Information Management},
  volume = {35},
  pages = {609--619},
  issn = {02684012},
  doi = {10.1016/j.ijinfomgt.2015.07.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401215000638},
  urldate = {2021-02-09},
  abstract = {Social media tools are integrated in most parts of our daily lives, as citizens, netizens, researchers or emergency responders. Lessons learnt from disasters and emergencies that occurred globally in the last few years have shown that social media tools may serve as an integral and significant component of crisis response. Communication is one of the fundamental tools of emergency management. It becomes crucial when there are dozens of agencies and organizations responding to a disaster. Regardless of the type of emergency, whether a terrorist attack, a hurricane or an earthquake, communication lines may be overloaded and cellular networks overwhelmed as too many people attempt to use them to access information. Social scientists have presented that post-disaster active public participation was largely altruistic, including activities such as search and rescue, first aid treatment, victim evacuation, and online help. Social media provides opportunities for engaging citizens in the emergency management by both disseminating information to the public and accessing information from them. During emergency events, individuals are exposed to large quantities of information without being aware of their validity or risk of misinformation, but users are usually swift to correct them, thus making the social media âself-regulatingâ.},
  file = {/Users/mark/Zotero/storage/AZJ5JY2N/Simon et al. - 2015 - Socializing in emergenciesâA review of the use of .pdf;/Users/mark/Zotero/storage/EGVAHNRP/Simon et al. - 2015 - Socializing in emergenciesâA review of the use of .pdf},
  langid = {english},
  number = {5}
}

@article{sonUsingHeuristicSystematicModel2020,
  title = {Using a {{Heuristic}}-{{Systematic Model}} to Assess the {{Twitter}} User Profileâs Impact on Disaster Tweet Credibility},
  author = {Son, Jaebong and Lee, Jintae and Oh, Onook and Lee, Hyung Koo and Woo, Jiyoung},
  date = {2020-10},
  journaltitle = {International Journal of Information Management},
  shortjournal = {International Journal of Information Management},
  volume = {54},
  pages = {102176},
  issn = {02684012},
  doi = {10.1016/j.ijinfomgt.2020.102176},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401219312526},
  urldate = {2021-02-09},
  abstract = {Journalists, emergency responders, and the general public use Twitter during disasters as an effective means to disseminate emergency information. However, there is a growing concern about the credibility of disaster tweets. This concern negatively influences Twitter usersâ decisions about whether to retweet information, which can delay the dissemination of accurateâand sometimes essentialâcommunications during a crisis. Although verifying information credibility is often a time-consuming task requiring considerable cognitive effort, researchers have yet to explore how people manage this task while using Twitter during disaster situations.},
  file = {/Users/mark/Zotero/storage/MKUQWYT9/Son et al. - 2020 - Using a Heuristic-Systematic Model to assess the T.pdf},
  langid = {english}
}

@book{tagarelliComputationalDataSocial2019,
  title = {Computational {{Data}} and {{Social Networks}}: 8th {{International Conference}}, {{CSoNet}} 2019, {{Ho Chi Minh City}}, {{Vietnam}}, {{November}} 18â20, 2019, {{Proceedings}}},
  shorttitle = {Computational {{Data}} and {{Social Networks}}},
  editor = {Tagarelli, Andrea and Tong, Hanghang},
  date = {2019},
  volume = {11917},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-34980-6},
  url = {http://link.springer.com/10.1007/978-3-030-34980-6},
  urldate = {2021-02-09},
  file = {/Users/mark/Zotero/storage/CAMC7A4J/Tagarelli and Tong - 2019 - Computational Data and Social Networks 8th Intern.pdf},
  isbn = {978-3-030-34979-0 978-3-030-34980-6},
  langid = {english},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@report{TREC2019AIncident2018,
  title = {{{TREC}} 2019-{{A Incident Streams Track}}.Pdf},
  date = {2018},
  file = {/Users/mark/Zotero/storage/UZ98AQ8S/TREC 2019-A Incident Streams Track.pdf}
}

@report{TREC2019BIncident2019,
  title = {{{TREC}} 2019-{{B Incident Streams Track}}.Pdf},
  date = {2019},
  file = {/Users/mark/Zotero/storage/YIMMSPUD/TREC 2019-B Incident Streams Track.pdf}
}

@inproceedings{tsolmonEventExtractionModel2014,
  title = {An Event Extraction Model Based on Timeline and User Analysis in {{Latent Dirichlet}} Allocation},
  booktitle = {Proceedings of the 37th International {{ACM SIGIR}} Conference on {{Research}} \& Development in Information Retrieval},
  author = {Tsolmon, Bayar and Lee, Kyung-Soon},
  date = {2014-07-03},
  pages = {1187--1190},
  publisher = {{ACM}},
  location = {{Gold Coast Queensland Australia}},
  doi = {10.1145/2600428.2609541},
  url = {https://dl.acm.org/doi/10.1145/2600428.2609541},
  urldate = {2021-02-09},
  abstract = {Social media such as Twitter has come to reflect the reaction of the general public to major events. Since posts are short and noisy, it is hard to extract reliable events based on word frequency. Even though an event term appears in a particularly low frequency, as long as at least one reliable user mentions the term, it should be extracted. This paper proposes an event extraction method which combines user reliability and timeline analysis. The Latent Dirichlet Allocation (LDA) topic model is adapted with the weights of event terms on timeline and reliable users to extract social events. The reliable users are detected on Twitter according to their tweeting behaviors: socially well-known users and active users. Reliable and low-frequency events can be detected based on reliable users In order to see the effectiveness of the proposed method, experiments are conducted on a Korean tweet collection; the proposed model achieved 72\% in precision. This shows that the LDA with timeline and reliable users is effective for extracting events on the Twitter test collection.},
  eventtitle = {{{SIGIR}} '14: {{The}} 37th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  file = {/Users/mark/Zotero/storage/C7AG8Z3P/Tsolmon and Lee - 2014 - An event extraction model based on timeline and us.pdf},
  isbn = {978-1-4503-2257-7},
  langid = {english}
}

@book{wangWebAgeInformationManagement2013,
  ids = {wangWebAgeInformationManagement2013a},
  title = {Web-{{Age Information Management}}},
  editor = {Wang, Jianyong and Xiong, Hui and Ishikawa, Yoshiharu and Xu, Jianliang and Zhou, Junfeng},
  date = {2013},
  volume = {7923},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-38562-9},
  url = {http://link.springer.com/10.1007/978-3-642-38562-9},
  urldate = {2021-02-09},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  file = {/Users/mark/Zotero/storage/2ZWFC99Q/Wang et al. - 2013 - Web-Age Information Management.pdf;/Users/mark/Zotero/storage/9HK99T8C/Wang et al. - 2013 - Web-Age Information Management.pdf},
  isbn = {978-3-642-38561-2 978-3-642-38562-9},
  langid = {english},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{wukichphdSocialMediaUse2015,
  ids = {wukichphdSocialMediaUse2015a},
  title = {Social Media Use in Emergency Management},
  author = {Wukich, PhD, Clayton},
  date = {2015-07-01},
  journaltitle = {Journal of Emergency Management},
  shortjournal = {JEM},
  volume = {13},
  pages = {281},
  issn = {1543-5865, 1543-5865},
  doi = {10.5055/jem.2015.0242},
  url = {http://www.wmpllc.org/ojs/index.php/jem/article/view/200},
  urldate = {2021-02-09},
  abstract = {Objective:\hspace{0.6em} To identify and illustrate the range of strategies and tactics available for emergency managers using social media. Design:\hspace{0.6em} This study uses content analysis of more than 80 related journal articles, research reports, and government documents as well as more than 120 newspaper articles, identified through LexisNexis search queries. Results:\hspace{0.6em}Three strategies, information dissemination, monitoring real-time data, and engaging the public in a conversation and/or crowdsourcing, are available to emergency managers to augment communication practices via face-to-face contact and through traditional media outlets. Academic research has identified several message types disseminated during response operations.1,2 Message types during other emergency phases have received less attention; however, news reporting and government reports provide best practices and inform this study. This article provides the foundation for a more complete typology of emergency management messages. Relatedly, despite limited attention in the academic research, monitoring social media feeds to accrue situational awareness and interacting with others to generate a conversation and/or to coordinate collective action also take place in various forms and are discussed. Conclusions:\hspace{0.6em}Findings integrate the fragmented body of knowledge into a more coherent whole and suggest that practitioners might maximize outcomes through a three-step process of information dissemination, data monitoring, and the direct engagement of diverse sets of actors to spur risk reduction efforts. However, these steps require time, personnel, and resources, which present},
  file = {/Users/mark/Zotero/storage/22RWDLBC/Wukich, PhD - 2015 - Social media use in emergency management.pdf;/Users/mark/Zotero/storage/Y6VB3XLB/Wukich, PhD - 2015 - Social media use in emergency management.pdf},
  langid = {english},
  number = {4}
}

@article{yangPhaseVis1WhatWhen2013,
  ids = {yangPhaseVis1WhatWhen2013a},
  title = {{{PhaseVis1}}: {{What}}, {{When}}, {{Where}}, and {{Who}} in {{Visualizing}} the {{Four Phases}} of {{Emergency Management Through}} the {{Lens}} of {{Social Media}}},
  author = {Yang, Seungwon and Chung, Haeyong and Lin, Xiao and Lee, Sunshin and Chen, Liangzhe and Wood, Andrew and Kavanaugh, Andrea L and Sheetz, Steven D and Shoemaker, Donald J and Fox, Edward A},
  date = {2013},
  pages = {6},
  abstract = {The Four Phase Model of Emergency Management has been widely used in developing emergency/disaster response plans. However, the model has received criticism contrasting the clear phase distinctions in the model with the complex and overlapping nature of phases indicated by empirical evidence. To investigate how phases actually occur, we designed PhaseVis based on visualization principles, and applied it to Hurricane Isaac tweet data. We trained three classification algorithms using the four phases as categories. The 10-fold cross-validation showed that Multi-class SVM performed the best in Precision (0.8) and NaÃ¯ve Bayes Multinomial performed the best in F-1 score (0.782). The tweet volume in each category was visualized as a ThemeRiverâ¢, which shows the âWhatâ aspect. Other aspects - 'When', 'Where', and 'Who' - are also integrated. The classification evaluation and a sample use case indicate that PhaseVis has potential utility in disasters, aiding those investigating a large disaster tweet dataset.},
  file = {/Users/mark/Zotero/storage/SUTYWCHN/Yang et al. - 2013 - PhaseVis1 What, When, Where, and Who in Visualizi.pdf;/Users/mark/Zotero/storage/UI24T563/Yang et al. - 2013 - PhaseVis1 What, When, Where, and Who in Visualizi.pdf},
  langid = {english}
}


