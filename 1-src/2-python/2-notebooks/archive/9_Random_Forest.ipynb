{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Algorithm\n",
    "# seeding the generated number makes our results reproducible (good for debugging)\n",
    "# This module implements pseudo-random number generators for various distributions.\n",
    "from csv import reader\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from random import randrange\n",
    "from random import seed\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as npX\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "#different models to compare:\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>priority</th>\n",
       "      <th>postCategories_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.430000e+02</td>\n",
       "      <td>943.000000</td>\n",
       "      <td>943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.029627e+17</td>\n",
       "      <td>0.387328</td>\n",
       "      <td>12.764581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.694446e+16</td>\n",
       "      <td>0.188837</td>\n",
       "      <td>5.135710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.115660e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.433901e+17</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.758353e+17</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.782131e+17</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.963364e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id    priority  postCategories_x\n",
       "count  9.430000e+02  943.000000        943.000000\n",
       "mean   3.029627e+17    0.387328         12.764581\n",
       "std    6.694446e+16    0.188837          5.135710\n",
       "min    2.115660e+17    0.000000          1.000000\n",
       "25%    2.433901e+17    0.250000          8.000000\n",
       "50%    2.758353e+17    0.250000         14.000000\n",
       "75%    3.782131e+17    0.500000         17.000000\n",
       "max    3.963364e+17    1.000000         23.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_int.csv\")\n",
    "#df1 = df.set_index('timestamp')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merged_df = pd.merge(tweet_to_category_id_priority_df, labels_df, left_on = 'tweet_id', right_on = 'postID', how = 'inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tweet_id', 'postCategories_x']]\n",
    "y = df['priority']\n",
    "\n",
    "#X = df.iloc[:, 1:4].values\n",
    "#y = df.iloc[:, 5].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.06800925925925927\n",
      "Mean Squared Error: 0.0154051669973545\n",
      "Root Mean Squared Error: 0.12411755313957208\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Classification Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-50e830509b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df.corr()\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.heatmap(corrmat, vmax=1, square=True,cmap=\"Greys\");\n",
    "ax.set_title('Correlation between model variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,model_name,df_acc,X_train, y_train,X_test,y_test):\n",
    "    now = time.time()\n",
    "    mdl = model()\n",
    "    mdl.fit(X_train, y_train)\n",
    "    preds_test = mdl.predict(X_test)\n",
    "    preds_train = mdl.predict(X_train)\n",
    "    #add to next row:\n",
    "    nr = len(df_acc)\n",
    "    df_acc.loc[nr,'model'] = model_name\n",
    "    df_acc.loc[nr,'test_accuracy'] = int(accuracy_score(y_test,preds_test)*100) #multiply by 100 for rough plotting\n",
    "    df_acc.loc[nr,'train_accuracy'] = int(accuracy_score(y_train,preds_train)*100)\n",
    "    df_acc.loc[nr,'time'] = int(time.time()-now)\n",
    "    return df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.DataFrame(columns = ['model','train_accuracy','test_accuracy','time'])\n",
    "\n",
    "#models to try:\n",
    "models = [LinearDiscriminantAnalysis,DecisionTreeClassifier,GaussianNB,KNeighborsClassifier,\n",
    "          RandomForestClassifier,MLPClassifier,LogisticRegression,LinearSVC]\n",
    "model_names = ['LDA','DecisionTree','GaussNaiveBayes','KNN','RandomForest','MLP','LogReg','LinSVC']\n",
    "\n",
    "#notes: for KNN, could tweak n_neighbors. \n",
    "\n",
    "for model, model_name in zip(models,model_names):\n",
    "    df_acc = get_accuracy(model,model_name,df_acc,X_train, y_train,X_test,y_test)\n",
    "    \n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterp(df_plot,x,y,ax,xlabel,ylabel,title):\n",
    "    df_plot.plot.scatter(x,y,ax = ax)\n",
    "    for i, txt in enumerate(df_plot.model):\n",
    "        ax.annotate(txt, (df_plot[x].iat[i]+1,df_plot[y].iat[i]-1),fontsize = 8)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "def make_scatter(df_plot):\n",
    "    df_plot[df_plot.columns[df_plot.columns != 'model']] = df_plot[df_plot.columns[df_plot.columns != 'model']].astype(int)\n",
    "    fig, axes = plt.subplots(1,2,figsize = [15,5])\n",
    "\n",
    "    # plot time vs test accuracy \n",
    "    scatterp(df_plot=df_acc,x='time',y='test_accuracy',ax=axes[0],xlabel='time (seconds)',\n",
    "             ylabel='test accuracy (percent)',title = 'Speed-accuracy trade-off: Test accuracy vs. time')\n",
    "\n",
    "    #plot train vs. test accuracy \n",
    "    scatterp(df_plot=df_acc,x='train_accuracy',y='test_accuracy',ax=axes[1],xlabel='train accuracy (percent)',\n",
    "             ylabel='test accuracy (percent)',title = 'Are we overfitting? Test accuracy vs. Train accuracy')\n",
    "\n",
    "\n",
    "make_scatter(df_plot=df_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['userFollowersCount', 'dict_f_measure']]\n",
    "y = df['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "### Split the dataset into 'Train' and 'Test' sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_features=2, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of RF classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on testing set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of RF classifier on training set: 0.39\n",
    "# Accuracy of RF classifier on testing set: 0.20\n",
    "\n",
    "# github.com/paulgureghian/Random_Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(X, y)\n",
    "# print(clf.predict([[0, 0,]]))\n",
    "# clf.feature_importances_\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())\n",
    "plt.title('Heatmap')\n",
    "plt.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box = df.drop(['negative_sentiment', 'dict_precision'], axis=1)\n",
    "df_box.boxplot()\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Features')\n",
    "plt.title('Boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, random_state = 1,n_jobs=-1)\n",
    "model_res = clf.fit(X_train_scaled, y_train)\n",
    "y_pred = model_res.predict(X_test_scaled)\n",
    "y_pred_prob = model_res.predict_proba(X_test_scaled)\n",
    "lr_probs = y_pred_prob[:,1]\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "# github.com/KalenWillits/RandomForest\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:30]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Plotting a confusion matrix allows us to discern whether the system is mislabelling a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names=['userFollowersCount', 'dict_f_measure'] # name  of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "#plt.savefig('figures/RF_cm_multi_class.png')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.savefig('figures/RF_cm_proportion_multi_class.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_the_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    \n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"Normalized confusion matrix\")\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)    \n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_the_confusion_matrix(cnf_matrix, target_names=class_names,title='Confusion matrix, without normalization')\n",
    "#plt.savefig('figures/RF_cm_multi_class.png')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, target_names=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.savefig('figures/RF_cm_proportion_multi_class.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trees: 1\n",
    "Scores: [44.40559440559441, 39.86013986013986, 39.51048951048951, 41.95804195804196, 44.05594405594406]\n",
    "Mean Accuracy: 41.958%\n",
    "Trees: 5\n",
    "Scores: [46.50349650349651, 39.51048951048951, 42.30769230769231, 47.2027972027972, 38.46153846153847]\n",
    "Mean Accuracy: 42.797%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    #init the dataset as a list\n",
    "\tdataset = list()\n",
    "    #open it as a readable file\n",
    "\twith open(filename, 'r') as file:\n",
    "        #init the csv reader\n",
    "\t\tcsv_reader = reader(file)\n",
    "        #for every row in the dataset\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "            #add that row as an element in our dataset list (2D Matrix of values)\n",
    "\t\t\tdataset.append(row)\n",
    "    #return in-memory data matrix\n",
    "\treturn dataset\n",
    " \n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    #iterate throw all the rows in our data matrix\n",
    "\tfor row in dataset:\n",
    "        #for the given column index, convert all values in that column to floats\n",
    "\t\trow[column] = float(row[column].strip())\n",
    " \n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    #store a given column \n",
    "    class_values = [row[column] for row in dataset]\n",
    "    #create an unordered collection with no duplicates, only unique valeus\n",
    "    unique = set(class_values)\n",
    "    #init a lookup table\n",
    "    lookup = dict()\n",
    "    #for each element in the column\n",
    "    for i, value in enumerate(unique):\n",
    "        #add it to our lookup table\n",
    "        lookup[value] = i\n",
    "    #the lookup table stores pointers to the strings\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    #return the lookup table\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "# the original sample is randomly partitioned into k equal sized subsamples. \n",
    "#Of the k subsamples, a single subsample is retained as the validation data \n",
    "#for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. \n",
    "#The cross-validation process is then repeated k times (the folds),\n",
    "#with each of the k subsamples used exactly once as the validation data.\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    #init 2 empty lists for storing split dataubsets\n",
    "\tleft, right = list(), list()\n",
    "    #for every row\n",
    "\tfor row in dataset:\n",
    "        #if the value at that row is less than the given value\n",
    "\t\tif row[index] < value:\n",
    "            #add it to list 1\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "            #else add it list 2 \n",
    "\t\t\tright.append(row)\n",
    "    #return both lists\n",
    "\treturn left, right\n",
    " \n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    #how many correct predictions?\n",
    "\tcorrect = 0\n",
    "    #for each actual label\n",
    "\tfor i in range(len(actual)):\n",
    "        #if actual matches predicted label\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "            #add 1 to the correct iterator\n",
    "\t\t\tcorrect += 1\n",
    "    #return percentage of predictions that were correct\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    #folds are the subsamples used to train and validate model\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "    #for each subsample\n",
    "\tfor fold in folds:\n",
    "        #create a copy of the data\n",
    "\t\ttrain_set = list(folds)\n",
    "        #remove the given subsample\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "        #init a test set\n",
    "\t\ttest_set = list()\n",
    "        #add each row in a given subsample to the test set\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "        #get predicted labls\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "        #get actual labels\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "        #compare accuracy\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "        #add it to scores list, for each fold\n",
    "\t\tscores.append(accuracy)\n",
    "    #return all accuracy scores\n",
    "\treturn scores\n",
    " \n",
    " \n",
    "# Calculate the Gini index for a split dataset\n",
    "# this is the name of the cost function used to evaluate splits in the dataset.\n",
    "# this is a measure of how often a randomly chosen element from the set \n",
    "# would be incorrectly labeled if it was randomly labeled according to the distribution\n",
    "# of labels in the subset. Can be computed by summing the probability\n",
    "# of an item with label i being chosen times the probability \n",
    "# of a mistake in categorizing that item. \n",
    "# It reaches its minimum (zero) when all cases in the node \n",
    "# fall into a single target category.\n",
    "# A split in the dataset involves one input attribute and one value for that attribute. \n",
    "# It can be used to divide training patterns into two groups of rows.\n",
    "# A Gini score gives an idea of how good a split is by how mixed the classes \n",
    "# are in the two groups created by the split. A perfect separation results in \n",
    "# a Gini score of 0, whereas the worst case split that results in 50/50 classes \n",
    "#in each group results in a Gini score of 1.0 (for a 2 class problem).\n",
    "#We first need to calculate the proportion of classes in each group.\n",
    "def gini_index(groups, class_values):\n",
    "\tgini = 0.0\n",
    "    #for each class\n",
    "\tfor class_value in class_values:\n",
    "        #a random subset of that class\n",
    "\t\tfor group in groups:\n",
    "\t\t\tsize = len(group)\n",
    "\t\t\tif size == 0:\n",
    "\t\t\t\tcontinue\n",
    "            #average of all class values\n",
    "\t\t\tproportion = [row[-1] for row in group].count(class_value) / float(size)\n",
    "            #  sum all (p * 1-p) values, this is gini index\n",
    "\t\t\tgini += (proportion * (1.0 - proportion))\n",
    "\treturn gini\n",
    " \n",
    "# Select the best split point for a dataset\n",
    "#This is an exhaustive and greedy algorithm\n",
    "def get_split(dataset, n_features):\n",
    "    ##Given a dataset, we must check every value on each attribute as a candidate split, \n",
    "    #evaluate the cost of the split and find the best possible split we could make.\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfeatures = list()\n",
    "\twhile len(features) < n_features:\n",
    "\t\tindex = randrange(len(dataset[0])-1)\n",
    "\t\tif index not in features:\n",
    "\t\t\tfeatures.append(index)\n",
    "\tfor index in features:\n",
    "\t\tfor row in dataset:\n",
    "            ##When selecting the best split and using it as a new node for the tree \n",
    "            #we will store the index of the chosen attribute, the value of that attribute \n",
    "            #by which to split and the two groups of data split by the chosen split point.\n",
    "            ##Each group of data is its own small dataset of just those rows assigned to the \n",
    "            #left or right group by the splitting process. You can imagine how we might split \n",
    "            #each group again, recursively as we build out our decision tree.\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    ##Once the best split is found, we can use it as a node in our decision tree.\n",
    "    ##We will use a dictionary to represent a node in the decision tree as \n",
    "    #we can store data by name. \n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    " \n",
    "# Create a terminal node value\n",
    "\n",
    "def to_terminal(group):\n",
    "    #select a class value for a group of rows. \n",
    "\toutcomes = [row[-1] for row in group]\n",
    "    #returns the most common output value in a list of rows.\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "#Create child splits for a node or make terminal\n",
    "#Building a decision tree involves calling the above developed get_split() function over \n",
    "#and over again on the groups created for each node.\n",
    "#New nodes added to an existing node are called child nodes. \n",
    "#A node may have zero children (a terminal node), one child (one side makes a prediction directly) \n",
    "#or two child nodes. We will refer to the child nodes as left and right in the dictionary representation \n",
    "#of a given node.\n",
    "#Once a node is created, we can create child nodes recursively on each group of data from \n",
    "#the split by calling the same function again.\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    #Firstly, the two groups of data split by the node are extracted for use and \n",
    "    #deleted from the node. As we work on these groups the node no longer requires access to these data.\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "    \n",
    "    #Next, we check if either left or right group of rows is empty and if so we create \n",
    "    #a terminal node using what records we do have.\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "    #We then check if we have reached our maximum depth and if so we create a terminal node.\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "    #We then process the left child, creating a terminal node if the group of rows is too small, \n",
    "    #otherwise creating and adding the left node in a depth first fashion until the bottom of \n",
    "    #the tree is reached on this branch.\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left, n_features)\n",
    "\t\tsplit(node['left'], max_depth, min_size, n_features, depth+1)\n",
    "\t# process right child\n",
    "    #The right side is then processed in the same manner, \n",
    "    #as we rise back up the constructed tree to the root.\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right, n_features)\n",
    "\t\tsplit(node['right'], max_depth, min_size, n_features, depth+1)\n",
    " \n",
    "#Build a decision tree\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    #Building the tree involves creating the root node and \n",
    "\troot = get_split(train, n_features)\n",
    "    #calling the split() function that then calls itself recursively to build out the whole tree.\n",
    "\tsplit(root, max_depth, min_size, n_features, 1)\n",
    "\treturn root\n",
    " \n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    #Making predictions with a decision tree involves navigating the \n",
    "    #tree with the specifically provided row of data.\n",
    "    #Again, we can implement this using a recursive function, where the same prediction routine is \n",
    "    #called again with the left or the right child nodes, depending on how the split affects the provided data.\n",
    "    #We must check if a child node is either a terminal value to be returned as the prediction\n",
    "    #, or if it is a dictionary node containing another level of the tree to be considered.\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    " \n",
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(dataset, ratio):\n",
    "\tsample = list()\n",
    "\tn_sample = round(len(dataset) * ratio)\n",
    "\twhile len(sample) < n_sample:\n",
    "\t\tindex = randrange(len(dataset))\n",
    "\t\tsample.append(dataset[index])\n",
    "\treturn sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a list of bagged trees\n",
    "#responsible for making a prediction with each decision tree and \n",
    "#combining the predictions into a single return value. \n",
    "#This is achieved by selecting the most common prediction \n",
    "#from the list of predictions made by the bagged trees.\n",
    "def bagging_predict(trees, row):\n",
    "\tpredictions = [predict(tree, row) for tree in trees]\n",
    "\treturn max(set(predictions), key=predictions.count)\n",
    " \n",
    "# Random Forest Algorithm\n",
    "#esponsible for creating the samples of the training dataset, training a decision tree on each,\n",
    "#then making predictions on the test dataset using the list of bagged trees.\n",
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "\ttrees = list()\n",
    "\tfor i in range(n_trees):\n",
    "\t\tsample = subsample(train, sample_size)\n",
    "\t\ttree = build_tree(sample, max_depth, min_size, n_features)\n",
    "\t\ttrees.append(tree)\n",
    "\tpredictions = [bagging_predict(trees, row) for row in test]\n",
    "\treturn(predictions)\n",
    "def random_1():\n",
    "    # Test the random forest algorithm\n",
    "    seed(1)\n",
    "    # load and prepare data\n",
    "    filename = 'feature_vec.csv'\n",
    "    dataset = load_csv(filename)\n",
    "    dataset.pop(0)\n",
    "    #print(dataset)\n",
    "    # convert string attributes to integers\n",
    "    for i in range(0, len(dataset[0])-1):\n",
    "        str_column_to_float(dataset, i)\n",
    "\n",
    "    # convert class column to integers\n",
    "    str_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "    # evaluate algorithm\n",
    "    n_folds = 5\n",
    "    max_depth = 10\n",
    "    min_size = 1\n",
    "    sample_size = 1.0\n",
    "    n_features = int(sqrt(len(dataset[0])-1))\n",
    "    for n_trees in [1, 5, 10]:\n",
    "        scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "        print('Trees: %d' % n_trees)\n",
    "        print('Scores: %s' % scores)\n",
    "        print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "        \n",
    "# random_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
