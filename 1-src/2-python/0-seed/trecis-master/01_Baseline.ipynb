{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import gzip\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "import sklearn.feature_extraction \n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pseudo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6074c7bb959f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id_map = {}\n",
    "with open(\"../data/2019b-testing.json\", \"r\") as in_file:\n",
    "    for line in in_file:\n",
    "        tweet_top = json.loads(line)\n",
    "        tweet = json.loads(tweet_top[\"allProperties\"][\"srcjson\"])\n",
    "        tweet_id_map[np.int64(tweet[\"id\"])] = tweet\n",
    "        \n",
    "with open(\"../data/2019b-training.json\", \"r\") as in_file:\n",
    "    for line in in_file:\n",
    "        tweet = json.loads(line)\n",
    "        tweet_id_map[np.int64(tweet[\"id\"])] = tweet\n",
    "\n",
    "print(\"Total Tweet Count:\", len(tweet_id_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_count_map = {}\n",
    "for lang in [tweet[\"lang\"] for tweet in tweet_id_map.values()]:\n",
    "    lang_count_map[lang] = lang_count_map.get(lang, 0) + 1\n",
    "lang_count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_count = 0\n",
    "domain_count_map = {}\n",
    "for entity in [tweet[\"entities\"] for tweet in tweet_id_map.values() if \"entities\" in tweet]:\n",
    "\n",
    "    if ( len(entity[\"urls\"]) > 0 ):\n",
    "        link_count += 1\n",
    "        \n",
    "        for url in entity[\"urls\"]:\n",
    "            domain = url[\"display_url\"].lower().partition(\"/\")[0]\n",
    "            domain_count_map[domain] = domain_count_map.get(domain, 0) + 1\n",
    "print(\"Tweets with Links:\", link_count)\n",
    "domain_count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count = 0\n",
    "for entity in [tweet[\"entities\"] for tweet in tweet_id_map.values() if \"entities\" in tweet]:\n",
    "\n",
    "    if ( \"media\" in entity ):\n",
    "#         print(entity[\"media\"])\n",
    "        img_count += 1\n",
    "print(\"Tweets with Images:\", img_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sources_map = {}\n",
    "\n",
    "for tweet in tweet_id_map.values():\n",
    "    tweet_sources_map[tweet[\"source\"]] = tweet_sources_map.get(tweet[\"source\"], 0) + 1\n",
    "\n",
    "print(\"Sources:\", len(tweet_sources_map))\n",
    "tweet_sources_index = {x:i+1 for i, x in enumerate([x for x in tweet_sources_map.keys()if tweet_sources_map[x] > 10])}\n",
    "\n",
    "print(\"Mapped Sources:\", len(tweet_sources_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_priority_map = {}\n",
    "priority_df = pd.read_csv(\"tweet_to_priority.csv\", dtype={\"tweet_id\": np.int64})\n",
    "for row in priority_df.itertuples():\n",
    "    tweet_id = row.tweet_id\n",
    "    \n",
    "    tweet_priority_map[tweet_id] = {\n",
    "        \"score\": row.score_mean,\n",
    "        \"weight\": 1.0 - row.score_std\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_category_map = {}\n",
    "category_df = pd.read_csv(\"tweet_to_category.csv\")\n",
    "\n",
    "cat_update_map = {\n",
    "    \"ContinuingNews\": \"News\",\n",
    "    \"PastNews\": \"ContextualInformation\",\n",
    "    \"KnownAlready\": \"OriginalEvent\",\n",
    "    \"SignificantEventChange\": \"NewSubEvent\",\n",
    "}\n",
    "\n",
    "category_df[\"category\"] = category_df[\"category\"].apply(lambda x: cat_update_map.get(x, x))\n",
    "\n",
    "for category, tweets in category_df.groupby(\"category\"):\n",
    "    tweet_category_map[category] = list(tweets[\"tweet_id\"])\n",
    "    \n",
    "# Deleted in 2019\n",
    "del(tweet_category_map[\"Unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, tweet_ids in tweet_category_map.items():\n",
    "    retrieved_count = sum([1 if np.int64(tid) in tweet_id_map else 0 in tweet_id_map for tid in tweet_ids])\n",
    "    print(\"Category:\", category)\n",
    "    print(\"\\tTweet Count:\", len(tweet_ids), \"Retrieved Fraction:\", retrieved_count/len(tweet_ids))\n",
    "    \n",
    "    lang_count_map = {}\n",
    "    for lang in [tweet_id_map[np.int64(tid)][\"lang\"] for tid in tweet_ids if int(tid) in tweet_id_map]:\n",
    "        lang_count_map[lang] = lang_count_map.get(lang, 0) + 1\n",
    "    print(\"\\t\", str(lang_count_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But first, read in stopwrods\n",
    "enStop = stopwords.words('english')\n",
    "\n",
    "# Skip stop words, retweet signs, @ symbols, and URL headers\n",
    "stopList = enStop +\\\n",
    "    [\"http\", \"https\", \"rt\", \"@\", \":\", \"t.co\", \"co\", \"amp\", \"&amp;\", \"...\", \"\\n\", \"\\r\"]\n",
    "stopList.extend(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizer_wrapper(text):\n",
    "#     return [t.lemma_ for t in nlp(text)]\n",
    "\n",
    "local_tokenizer = TweetTokenizer()\n",
    "def tokenizer_wrapper(text):\n",
    "    return local_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Additional Features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "## Taken from Davidson et al.\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    tweet_text = tweet[\"text\"]\n",
    "    \n",
    "    ##SENTIMENT\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet_text)\n",
    "    \n",
    "    words = local_tokenizer.tokenize(tweet_text) #Get text only\n",
    "    \n",
    "    num_chars = sum(len(w) for w in words) #num chars in words\n",
    "    num_chars_total = len(tweet_text)\n",
    "    num_terms = len(tweet_text.split())\n",
    "    num_words = len(words)\n",
    "    num_unique_terms = len(set([x.lower() for x in words]))\n",
    "    \n",
    "    caps_count = sum([1 if x.isupper() else 0 for x in tweet_text])\n",
    "    caps_ratio = caps_count / num_chars_total\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet_text) #Count #, @, and http://\n",
    "    num_media = 0\n",
    "    if \"entities\" in tweet and \"media\" in tweet[\"entities\"]:\n",
    "        num_media = len(tweet[\"entities\"][\"media\"])\n",
    "    retweet = 0\n",
    "    if \"rt\" in words or \"retweeted_status\" in tweet:\n",
    "        retweet = 1\n",
    "        \n",
    "    has_place = 1 if \"coordinates\" in tweet else 0\n",
    "        \n",
    "    author = tweet[\"user\"]\n",
    "    is_verified = 1 if (\"verified\" in author and author[\"verified\"]) else 0\n",
    "    log_followers = 0\n",
    "    if \"followers_count\" in author and author[\"followers_count\"] > 0:\n",
    "         log_followers = np.log(author[\"followers_count\"])\n",
    "    log_friends = 0\n",
    "    if \"friends_count\" in author and author[\"friends_count\"] > 0:\n",
    "         log_followers = np.log(author[\"friends_count\"])\n",
    "    \n",
    "    features = [num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], \n",
    "                sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet, num_media,\n",
    "                is_verified, \n",
    "#                 log_followers, log_friends,\n",
    "#                 has_place,\n",
    "                caps_ratio,\n",
    "               ]\n",
    "\n",
    "    return [round(x, 4) for x in features]\n",
    "\n",
    "other_features_names = [\"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\n",
    "                        \"vader neu\", \"vader compound\", \\\n",
    "                        \"num_hashtags\", \"num_mentions\", \n",
    "                        \"num_urls\", \"is_retweet\", \"num_media\",\n",
    "                        \"is_verified\", \n",
    "#                         \"log_followers\", \"log_friends\",\n",
    "#                         \"has_place\",\n",
    "                        \"caps_ratio\",\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_label = {c:i+1 for i, c in enumerate(tweet_category_map.keys()) if c != \"Irrelevant\"}\n",
    "category_to_label[\"Irrelevant\"] = 0\n",
    "\n",
    "tweet_id_to_category = {}\n",
    "for category, tweet_ids in tweet_category_map.items():\n",
    "    if ( len(tweet_ids) < 5 ):\n",
    "        print(\"Skipping category:\", category)\n",
    "        continue\n",
    "        \n",
    "    for tweet_id in tweet_ids:\n",
    "        tweet_id_to_category[np.int64(tweet_id)] = category_to_label[category]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_pairs = [(tweet, tweet_id_to_category[tid]) \n",
    "#                for tid, tweet in tweet_id_map.items() if tid in tweet_id_to_category]\n",
    "\n",
    "tweet_pairs = [(tweet_id_map[np.int64(tweet)], category_to_label[category]) \n",
    "               for category, tweet_ids in tweet_category_map.items() for tweet in tweet_ids]\n",
    "\n",
    "tweet_texts = [tp[0][\"text\"] for tp in tweet_pairs]\n",
    "\n",
    "y_data = np.array([tp[1] for tp in tweet_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tweets with Categories:\", y_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "vectorizer = joblib.load(\"../models/2013to2016_tfidf_vectorizer_20190109.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.transform(tweet_texts).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ftr_data = np.array([other_features(tweet) for tweet, _ in tweet_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_ftrs = [tweet_sources_index.get(tweet[\"source\"], 0) for tweet, _ in tweet_pairs]\n",
    "\n",
    "source_ftr_onehot = []\n",
    "for ftr in sources_ftrs:\n",
    "    f = np.zeros(len(tweet_sources_index) + 1)\n",
    "    f[ftr] = 1.0\n",
    "    source_ftr_onehot.append(f)\n",
    "\n",
    "sources_ftr_data = np.array(source_ftr_onehot)    \n",
    "\n",
    "sources_ftr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([\n",
    "    tfidf, \n",
    "    other_ftr_data, \n",
    "    sources_ftr_data,\n",
    "], axis=1)\n",
    "\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_names_ = np.concatenate([\n",
    "    np.array([x for x in vocab]), \n",
    "    other_features_names, \n",
    "    [\"Unknown\"] + list(tweet_sources_index.keys()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dictionary Word Count:\", len(vocab))\n",
    "print([x[0] for x in vocab.items()][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_state = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_number_list = list(category_to_label.values())\n",
    "d = len(category_number_list)\n",
    "\n",
    "f1_accum = []\n",
    "accuracy_accum = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=r_state)\n",
    "for train, test in skf.split(X_data, y_data):\n",
    "\n",
    "    # Get actual labels\n",
    "    y_test = y_data[test]\n",
    "\n",
    "    # Compute Precision-Recall \n",
    "    y_infer_local = [category_number_list[np.random.randint(0, d)] for smaple in y_test]\n",
    "    f1_accum.append(f1_score(y_test, y_infer_local, average=\"macro\"))\n",
    "    \n",
    "    accuracy_accum.append(sklearn.metrics.accuracy_score(y_test, y_infer_local))\n",
    "\n",
    "print(\"Accuracy:\", np.mean(accuracy_accum))\n",
    "print(\"F1:\", np.mean(f1_accum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': 128, \n",
    "    \"n_jobs\": -1,\n",
    "    'random_state': r_state,\n",
    "    'class_weight': \"balanced\",\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 32,\n",
    "    'max_features': 113,\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 54,\n",
    "}\n",
    "\n",
    "nb_params = {\n",
    "    'alpha': 0.01579145221181444,\n",
    "    'binarize': 0.7316900686676242,\n",
    "    'fit_prior': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_accum = []\n",
    "accuracy_accum = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=r_state)\n",
    "for train, test in skf.split(X_data, y_data):\n",
    "\n",
    "    X_train = X_data[train]\n",
    "    y_train = y_data[train]\n",
    "    \n",
    "    X_test = X_data[test]\n",
    "    y_test = y_data[test]\n",
    "\n",
    "    # train\n",
    "#     fitted_model = RandomForestClassifier(**rf_params)\n",
    "    fitted_model = BernoulliNB(**nb_params)\n",
    "    fitted_model.fit(X_train, y_train)\n",
    "\n",
    "    # Compute Precision-Recall \n",
    "    y_infer_local = fitted_model.predict(X_test)\n",
    "    local_f1 = f1_score(y_test, y_infer_local, average=\"macro\")\n",
    "    local_score = fitted_model.score(X_test, y_test)\n",
    "    print(\"\\tAccuracy:\", local_score)\n",
    "    print(\"\\tF1:\", local_f1)\n",
    "    \n",
    "    f1_accum.append(local_f1)\n",
    "    accuracy_accum.append(local_score)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(accuracy_accum))\n",
    "print(\"F1:\", np.mean(f1_accum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_to_category = {j:i for i, j in category_to_label.items()}\n",
    "for positive_category in category_number_list:\n",
    "    local_y_data = [1 if y == positive_category else 0 for y in y_data]\n",
    "    \n",
    "    fitted_model = RandomForestClassifier(**rf_params)\n",
    "    fitted_model.fit(X_data, local_y_data)\n",
    "    \n",
    "    weights = [(ftr_names_[idx], coef) \n",
    "               for idx, coef in enumerate(fitted_model.feature_importances_)]\n",
    "\n",
    "    tops = sorted(weights, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(\"Label:\", label_to_category[positive_category])\n",
    "    print(\"Score:\", fitted_model.score(X_data, local_y_data))\n",
    "    for token, weight in tops:\n",
    "        print(\"\\t\", token, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smapper(x):\n",
    "    if ( x < 0.75 ):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "y_data_regress = np.array([smapper(tweet_priority_map[np.int64(tp[0][\"id\"])][\"score\"]) \n",
    "                           for tp in tweet_pairs])\n",
    "y_data_weights = np.array([tweet_priority_map[np.int64(tp[0][\"id\"])][\"weight\"] \n",
    "                           for tp in tweet_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_accum = []\n",
    "f1_accum = []\n",
    "accuracy_accum = []\n",
    "\n",
    "rf_priority_params = {\n",
    "    'random_state': r_state,\n",
    "    'class_weight': 'balanced',\n",
    "    'n_estimators': 128, \n",
    "    'n_jobs': -1,\n",
    "    'max_depth': 50,\n",
    "    'max_features': 14,\n",
    "    'min_samples_leaf': 33,\n",
    "    'min_samples_split': 96,\n",
    "}\n",
    "\n",
    "nb_priority_params = {\n",
    "    'alpha': 0.05134305647695325,\n",
    "    'binarize': 0.045909955637688404,\n",
    "    'fit_prior': True,\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=r_state)\n",
    "for train, test in skf.split(X_data, y_data_regress):\n",
    "\n",
    "    X_train = X_data[train]\n",
    "    y_train = y_data_regress[train]\n",
    "    y_weight = y_data_weights[train]\n",
    "    \n",
    "    X_test = X_data[test]\n",
    "    y_test = y_data_regress[test]\n",
    "\n",
    "    # train\n",
    "    print(\"\\tFitting...\")\n",
    "#     fitted_model = sklearn.linear_model.LinearRegression(n_jobs=4)\n",
    "#     fitted_model = sklearn.tree.DecisionTreeRegressor(random_state=r_state, max_depth=256)\n",
    "    fitted_model = BernoulliNB(**nb_priority_params)\n",
    "#     fitted_model = RandomForestClassifier(**rf_priority_params)\n",
    "    fitted_model.fit(X_train, y_train, y_weight)\n",
    "\n",
    "    # Compute score metrics\n",
    "    r2_score = fitted_model.score(X_test, y_test)\n",
    "    score_accum.append(r2_score)\n",
    "    \n",
    "    # Compute Precision-Recall \n",
    "    y_infer_local = fitted_model.predict(X_test)\n",
    "    f1_accum.append(f1_score(y_test, y_infer_local, average=\"macro\"))\n",
    "    \n",
    "    accuracy_accum.append(fitted_model.score(X_test, y_test))\n",
    "    \n",
    "    print(\"\\t\", r2_score)\n",
    "\n",
    "print(\"Score (R^2):\", np.mean(score_accum))\n",
    "print(\"Accuracy:\", np.mean(accuracy_accum))\n",
    "print(\"F1:\", np.mean(f1_accum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X_data, y_data, clf, param_dist, n_iter_search=20, r_state=1337):\n",
    "    # run randomized search\n",
    "    random_search = RandomizedSearchCV(clf, \n",
    "                                       param_distributions=param_dist,\n",
    "                                       n_iter=n_iter_search,\n",
    "                                       cv=10,\n",
    "                                       scoring=\"f1_macro\",\n",
    "                                       random_state=r_state,\n",
    "                                       verbose=2,\n",
    "                                       n_jobs=16,\n",
    "                                      )\n",
    "    \n",
    "    random_search.fit(X_data, y_data)\n",
    "\n",
    "    return (random_search.best_score_, random_search.best_params_)\n",
    "\n",
    "def model_eval_rf(X_data, y_data, n_iter_search=100, r_state=1337):\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=100, class_weight=\"balanced\", random_state=r_state)\n",
    "    \n",
    "    # specify parameters and distributions to sample from\n",
    "    param_dist = {\n",
    "        \"max_depth\": [2, 4, 8, 16, 32, 64, 128, None],\n",
    "        \"max_features\": scipy.stats.randint(1, 512),\n",
    "        \"min_samples_split\": scipy.stats.randint(2, 512),\n",
    "        \"min_samples_leaf\": scipy.stats.randint(2, 512),\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "    }\n",
    "    \n",
    "    return random_search(X_data, y_data, clf, param_dist, n_iter_search=n_iter_search, r_state=r_state)\n",
    "\n",
    "def model_eval_nb(X_data, y_data, n_iter_search=100, r_state=1337):\n",
    "\n",
    "    clf = BernoulliNB()\n",
    "    \n",
    "    # specify parameters and distributions to sample from\n",
    "    param_dist = {\n",
    "        \"alpha\": scipy.stats.uniform(),\n",
    "        \"binarize\": scipy.stats.uniform(),\n",
    "        \"fit_prior\": [True, False],\n",
    "    }\n",
    "    \n",
    "    return random_search(X_data, y_data, clf, param_dist, n_iter_search=n_iter_search, r_state=r_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_results = model_eval_nb(X_data, y_data_regress, n_iter_search=128)\n",
    "# search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = []\n",
    "with open(\"../data/2019b-testing.json\", \"r\") as in_file:\n",
    "    for line in in_file:\n",
    "        tweet_top = json.loads(line)\n",
    "        tweet = json.loads(tweet_top[\"allProperties\"][\"srcjson\"])\n",
    "        test_tweets.append(tweet)\n",
    "        \n",
    "X_test_tfidf = vectorizer.transform([t[\"text\"] for t in test_tweets]).toarray()\n",
    "X_test_other = np.array([other_features(tweet) for tweet in test_tweets])\n",
    "\n",
    "sources_ftrs = [tweet_sources_index.get(tweet[\"source\"], 0) for tweet in test_tweets]\n",
    "source_ftr_onehot = []\n",
    "for ftr in sources_ftrs:\n",
    "    f = np.zeros(len(tweet_sources_index) + 1)\n",
    "    f[ftr] = 1.0\n",
    "    source_ftr_onehot.append(f)\n",
    "X_test_sources = np.array(source_ftr_onehot)    \n",
    "\n",
    "X_test_data = np.concatenate([\n",
    "    X_test_tfidf, \n",
    "    X_test_other, \n",
    "    X_test_sources,\n",
    "], axis=1)\n",
    "\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = BernoulliNB(**nb_params)\n",
    "fitted_model.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = fitted_model.predict(X_test_data)\n",
    "\n",
    "labeled_test_data = list(zip([t[\"id\"] for t in test_tweets], y_test_labels))\n",
    "\n",
    "id_to_cat_map = {y:x for x,y in category_to_label.items()}\n",
    "\n",
    "df = pd.DataFrame([{\"tweet_id\":tup[0], \"label\": id_to_cat_map[tup[1]]} for tup in labeled_test_data])\n",
    "\n",
    "df.to_csv(\"trec2019b_test_results_run_baseline.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted_pri_model = BernoulliNB(**nb_params)\n",
    "fitted_pri_model = RandomForestClassifier(**rf_priority_params)\n",
    "fitted_pri_model.fit(X_data, y_data_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = fitted_pri_model.predict(X_test_data)\n",
    "\n",
    "labeled_test_data = list(zip([t[\"id\"] for t in test_tweets], y_test_labels))\n",
    "\n",
    "df = pd.DataFrame([{\"tweet_id\":tup[0], \"priority\": tup[1]} for tup in labeled_test_data])\n",
    "\n",
    "df.to_csv(\"trec2019b_test_results_priority_run_baseline.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"priority\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Multiple Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pairs = []\n",
    "y_data = []\n",
    "\n",
    "indexer = {c:i for i, c in enumerate(list(category_to_label.keys()))}\n",
    "indexer_inv = {i:c for c,i in indexer.items()}\n",
    "for tweet_id, categories in category_df.groupby(\"tweet_id\"):\n",
    "    \n",
    "    tup = (\n",
    "        tweet_id_map[np.int64(tweet_id)], \n",
    "        [indexer[category] for category in categories[\"category\"] if category != 'Unknown']\n",
    "    )\n",
    "    tweet_pairs.append(tup)\n",
    "\n",
    "tweet_texts = [tp[0][\"text\"] for tp in tweet_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_ = [tp[1] for tp in tweet_pairs]\n",
    "\n",
    "def one_hot_y(y_list):\n",
    "    encoded = [0] * len(indexer)\n",
    "    for y in y_list:\n",
    "        encoded[y] = 1\n",
    "    return encoded\n",
    "\n",
    "y_data = np.array([one_hot_y(y) for y in y_data_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.transform(tweet_texts).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ftr_data = np.array([other_features(tweet) for tweet, _ in tweet_pairs])\n",
    "other_ftr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_ftrs = [tweet_sources_index.get(tweet[\"source\"], 0) for tweet, _ in tweet_pairs]\n",
    "source_ftr_onehot = []\n",
    "for ftr in sources_ftrs:\n",
    "    f = np.zeros(len(tweet_sources_index) + 1)\n",
    "    f[ftr] = 1.0\n",
    "    source_ftr_onehot.append(f)\n",
    "X_test_sources = np.array(source_ftr_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([\n",
    "    tfidf, \n",
    "    other_ftr_data, \n",
    "    X_test_sources,\n",
    "], axis=1)\n",
    "\n",
    "ftr_names_ = np.concatenate([\n",
    "    np.array([x for x in vocab]), \n",
    "    other_features_names, \n",
    "    [\"Unknown\"] + list(tweet_sources_index.keys()),\n",
    "])\n",
    "\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=10, random_state=r_state)\n",
    "for train, test in skf.split(X_data, y_data):\n",
    "\n",
    "    X_train = X_data[train]    \n",
    "    X_test = X_data[test]\n",
    "    \n",
    "    y_train = y_data[train]\n",
    "    y_test = y_data[test]\n",
    "\n",
    "\n",
    "    # train\n",
    "    fitted_model = sklearn.multiclass.OneVsRestClassifier(\n",
    "#         RandomForestClassifier(**rf_params)\n",
    "        BernoulliNB(**nb_params)\n",
    "    )\n",
    "    fitted_model.fit(X_train, y_train)\n",
    "\n",
    "    # Compute Precision-Recall \n",
    "    y_infer_local = fitted_model.predict(X_test)\n",
    "    local_f1 = f1_score(y_test, y_infer_local, average=\"weighted\")\n",
    "    local_score = fitted_model.score(X_test, y_test)\n",
    "    print(\"\\tAccuracy:\", local_score)\n",
    "    print(\"\\tF1:\", local_f1)\n",
    "    \n",
    "    f1_accum.append(local_f1)\n",
    "    accuracy_accum.append(local_score)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(accuracy_accum))\n",
    "print(\"F1:\", np.mean(f1_accum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = fitted_model.predict(X_test)\n",
    "prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, x in enumerate(prs.sum(axis=0)):\n",
    "    print(i, indexer_inv[i], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.multiclass.OneVsRestClassifier(\n",
    "#         RandomForestClassifier(**rf_params)\n",
    "    BernoulliNB(**nb_params)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = clf.predict(X_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "for tid, row_labels in zip([t[\"id\"] for t in test_tweets], y_test_labels):\n",
    "    \n",
    "    row = [tid] + row_labels.tolist()\n",
    "    all_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_to_cat_map = {y:x for x,y in category_to_label.items()}\n",
    "\n",
    "df = pd.DataFrame(all_rows, columns=[\"tweet_id\"] + [indexer_inv[i] for i in range(len(indexer_inv))])\n",
    "\n",
    "df.to_csv(\"trec2019b_test_results_run_baseline_multi.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
