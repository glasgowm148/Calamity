{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Algorithm\n",
    "#This module implements pseudo-random number generators for various distributions.\n",
    "#seeding the generated number makes our results reproducible (good for debugging)\n",
    "from random import seed\n",
    "#Return a randomly selected element from range(start, stop, step). \n",
    "from random import randrange\n",
    "#read CSV file (dataset)\n",
    "from csv import reader\n",
    "#square root function\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    #init the dataset as a list\n",
    "\tdataset = list()\n",
    "    #open it as a readable file\n",
    "\twith open(filename, 'r') as file:\n",
    "        #init the csv reader\n",
    "\t\tcsv_reader = reader(file)\n",
    "        #for every row in the dataset\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "            #add that row as an element in our dataset list (2D Matrix of values)\n",
    "\t\t\tdataset.append(row)\n",
    "    #return in-memory data matrix\n",
    "\treturn dataset\n",
    " \n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    #iterate throw all the rows in our data matrix\n",
    "\tfor row in dataset:\n",
    "        #for the given column index, convert all values in that column to floats\n",
    "\t\trow[column] = float(row[column].strip())\n",
    " \n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    #store a given column \n",
    "    class_values = [row[column] for row in dataset]\n",
    "    #create an unordered collection with no duplicates, only unique valeus\n",
    "    unique = set(class_values)\n",
    "    #init a lookup table\n",
    "    lookup = dict()\n",
    "    #for each element in the column\n",
    "    for i, value in enumerate(unique):\n",
    "        #add it to our lookup table\n",
    "        lookup[value] = i\n",
    "    #the lookup table stores pointers to the strings\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    #return the lookup table\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "# the original sample is randomly partitioned into k equal sized subsamples. \n",
    "#Of the k subsamples, a single subsample is retained as the validation data \n",
    "#for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. \n",
    "#The cross-validation process is then repeated k times (the folds),\n",
    "#with each of the k subsamples used exactly once as the validation data.\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    #init 2 empty lists for storing split dataubsets\n",
    "\tleft, right = list(), list()\n",
    "    #for every row\n",
    "\tfor row in dataset:\n",
    "        #if the value at that row is less than the given value\n",
    "\t\tif row[index] < value:\n",
    "            #add it to list 1\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "            #else add it list 2 \n",
    "\t\t\tright.append(row)\n",
    "    #return both lists\n",
    "\treturn left, right\n",
    " \n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    #how many correct predictions?\n",
    "\tcorrect = 0\n",
    "    #for each actual label\n",
    "\tfor i in range(len(actual)):\n",
    "        #if actual matches predicted label\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "            #add 1 to the correct iterator\n",
    "\t\t\tcorrect += 1\n",
    "    #return percentage of predictions that were correct\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    #folds are the subsamples used to train and validate model\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "    #for each subsample\n",
    "\tfor fold in folds:\n",
    "        #create a copy of the data\n",
    "\t\ttrain_set = list(folds)\n",
    "        #remove the given subsample\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "        #init a test set\n",
    "\t\ttest_set = list()\n",
    "        #add each row in a given subsample to the test set\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "        #get predicted labls\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "        #get actual labels\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "        #compare accuracy\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "        #add it to scores list, for each fold\n",
    "\t\tscores.append(accuracy)\n",
    "    #return all accuracy scores\n",
    "\treturn scores\n",
    " \n",
    " \n",
    "# Calculate the Gini index for a split dataset\n",
    "## this is the name of the cost function used to evaluate splits in the dataset.\n",
    "# this is a measure of how often a randomly chosen element from the set \n",
    "#would be incorrectly labeled if it was randomly labeled according to the distribution\n",
    "#of labels in the subset. Can be computed by summing the probability\n",
    "#of an item with label i being chosen times the probability \n",
    "#of a mistake in categorizing that item. \n",
    "#It reaches its minimum (zero) when all cases in the node \n",
    "#fall into a single target category.\n",
    "#A split in the dataset involves one input attribute and one value for that attribute. \n",
    "#It can be used to divide training patterns into two groups of rows.\n",
    "#A Gini score gives an idea of how good a split is by how mixed the classes \n",
    "#are in the two groups created by the split. A perfect separation results in \n",
    "#a Gini score of 0, whereas the worst case split that results in 50/50 classes \n",
    "#in each group results in a Gini score of 1.0 (for a 2 class problem).\n",
    "#We first need to calculate the proportion of classes in each group.\n",
    "def gini_index(groups, class_values):\n",
    "\tgini = 0.0\n",
    "    #for each class\n",
    "\tfor class_value in class_values:\n",
    "        #a random subset of that class\n",
    "\t\tfor group in groups:\n",
    "\t\t\tsize = len(group)\n",
    "\t\t\tif size == 0:\n",
    "\t\t\t\tcontinue\n",
    "            #average of all class values\n",
    "\t\t\tproportion = [row[-1] for row in group].count(class_value) / float(size)\n",
    "            #  sum all (p * 1-p) values, this is gini index\n",
    "\t\t\tgini += (proportion * (1.0 - proportion))\n",
    "\treturn gini\n",
    " \n",
    "# Select the best split point for a dataset\n",
    "#This is an exhaustive and greedy algorithm\n",
    "def get_split(dataset, n_features):\n",
    "    ##Given a dataset, we must check every value on each attribute as a candidate split, \n",
    "    #evaluate the cost of the split and find the best possible split we could make.\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfeatures = list()\n",
    "\twhile len(features) < n_features:\n",
    "\t\tindex = randrange(len(dataset[0])-1)\n",
    "\t\tif index not in features:\n",
    "\t\t\tfeatures.append(index)\n",
    "\tfor index in features:\n",
    "\t\tfor row in dataset:\n",
    "            ##When selecting the best split and using it as a new node for the tree \n",
    "            #we will store the index of the chosen attribute, the value of that attribute \n",
    "            #by which to split and the two groups of data split by the chosen split point.\n",
    "            ##Each group of data is its own small dataset of just those rows assigned to the \n",
    "            #left or right group by the splitting process. You can imagine how we might split \n",
    "            #each group again, recursively as we build out our decision tree.\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    ##Once the best split is found, we can use it as a node in our decision tree.\n",
    "    ##We will use a dictionary to represent a node in the decision tree as \n",
    "    #we can store data by name. \n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    " \n",
    "# Create a terminal node value\n",
    "\n",
    "def to_terminal(group):\n",
    "    #select a class value for a group of rows. \n",
    "\toutcomes = [row[-1] for row in group]\n",
    "    #returns the most common output value in a list of rows.\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "#Create child splits for a node or make terminal\n",
    "#Building a decision tree involves calling the above developed get_split() function over \n",
    "#and over again on the groups created for each node.\n",
    "#New nodes added to an existing node are called child nodes. \n",
    "#A node may have zero children (a terminal node), one child (one side makes a prediction directly) \n",
    "#or two child nodes. We will refer to the child nodes as left and right in the dictionary representation \n",
    "#of a given node.\n",
    "#Once a node is created, we can create child nodes recursively on each group of data from \n",
    "#the split by calling the same function again.\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    #Firstly, the two groups of data split by the node are extracted for use and \n",
    "    #deleted from the node. As we work on these groups the node no longer requires access to these data.\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "    \n",
    "    #Next, we check if either left or right group of rows is empty and if so we create \n",
    "    #a terminal node using what records we do have.\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "    #We then check if we have reached our maximum depth and if so we create a terminal node.\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "    #We then process the left child, creating a terminal node if the group of rows is too small, \n",
    "    #otherwise creating and adding the left node in a depth first fashion until the bottom of \n",
    "    #the tree is reached on this branch.\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left, n_features)\n",
    "\t\tsplit(node['left'], max_depth, min_size, n_features, depth+1)\n",
    "\t# process right child\n",
    "    #The right side is then processed in the same manner, \n",
    "    #as we rise back up the constructed tree to the root.\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right, n_features)\n",
    "\t\tsplit(node['right'], max_depth, min_size, n_features, depth+1)\n",
    " \n",
    "#Build a decision tree\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    #Building the tree involves creating the root node and \n",
    "\troot = get_split(train, n_features)\n",
    "    #calling the split() function that then calls itself recursively to build out the whole tree.\n",
    "\tsplit(root, max_depth, min_size, n_features, 1)\n",
    "\treturn root\n",
    " \n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    #Making predictions with a decision tree involves navigating the \n",
    "    #tree with the specifically provided row of data.\n",
    "    #Again, we can implement this using a recursive function, where the same prediction routine is \n",
    "    #called again with the left or the right child nodes, depending on how the split affects the provided data.\n",
    "    #We must check if a child node is either a terminal value to be returned as the prediction\n",
    "    #, or if it is a dictionary node containing another level of the tree to be considered.\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    " \n",
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(dataset, ratio):\n",
    "\tsample = list()\n",
    "\tn_sample = round(len(dataset) * ratio)\n",
    "\twhile len(sample) < n_sample:\n",
    "\t\tindex = randrange(len(dataset))\n",
    "\t\tsample.append(dataset[index])\n",
    "\treturn sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a list of bagged trees\n",
    "#responsible for making a prediction with each decision tree and \n",
    "#combining the predictions into a single return value. \n",
    "#This is achieved by selecting the most common prediction \n",
    "#from the list of predictions made by the bagged trees.\n",
    "def bagging_predict(trees, row):\n",
    "\tpredictions = [predict(tree, row) for tree in trees]\n",
    "\treturn max(set(predictions), key=predictions.count)\n",
    " \n",
    "# Random Forest Algorithm\n",
    "#esponsible for creating the samples of the training dataset, training a decision tree on each,\n",
    "#then making predictions on the test dataset using the list of bagged trees.\n",
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "\ttrees = list()\n",
    "\tfor i in range(n_trees):\n",
    "\t\tsample = subsample(train, sample_size)\n",
    "\t\ttree = build_tree(sample, max_depth, min_size, n_features)\n",
    "\t\ttrees.append(tree)\n",
    "\tpredictions = [bagging_predict(trees, row) for row in test]\n",
    "\treturn(predictions)\n",
    " \n",
    "# Test the random forest algorithm\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'feature_vec.csv'\n",
    "dataset = load_csv(filename)\n",
    "dataset.pop(0)\n",
    "#print(dataset)\n",
    "# convert string attributes to integers\n",
    "for i in range(0, len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "max_depth = 10\n",
    "min_size = 1\n",
    "sample_size = 1.0\n",
    "n_features = int(sqrt(len(dataset[0])-1))\n",
    "for n_trees in [1, 5, 10]:\n",
    "\tscores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "\tprint('Trees: %d' % n_trees)\n",
    "\tprint('Scores: %s' % scores)\n",
    "\tprint('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trees: 1\n",
    "Scores: [44.40559440559441, 39.86013986013986, 39.51048951048951, 41.95804195804196, 44.05594405594406]\n",
    "Mean Accuracy: 41.958%\n",
    "Trees: 5\n",
    "Scores: [46.50349650349651, 39.51048951048951, 42.30769230769231, 47.2027972027972, 38.46153846153847]\n",
    "Mean Accuracy: 42.797%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as npX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>numb_of_mentions</th>\n",
       "      <th>numb_of_urls</th>\n",
       "      <th>numb_of_hashtagsnumb_of_personal_pronouns</th>\n",
       "      <th>numb_of_present_tenses</th>\n",
       "      <th>numb_of_past_tenses</th>\n",
       "      <th>sent_from_web</th>\n",
       "      <th>...</th>\n",
       "      <th>numb_of_intensifiers</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>userFollowersCount</th>\n",
       "      <th>userFriendsCount</th>\n",
       "      <th>user_numb_of_tweets</th>\n",
       "      <th>user_list_count</th>\n",
       "      <th>tfidf_fire</th>\n",
       "      <th>dict_precision</th>\n",
       "      <th>dict_recall</th>\n",
       "      <th>dict_f_measure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.565106e+12</th>\n",
       "      <td>0</td>\n",
       "      <td>1.158763e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>14.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.158762e+18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>13.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>2</td>\n",
       "      <td>1.158760e+18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>26.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>3</td>\n",
       "      <td>1.158759e+18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>22.219999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>4</td>\n",
       "      <td>1.158759e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565027e+12</th>\n",
       "      <td>1428</td>\n",
       "      <td>1.158432e+18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>11.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565027e+12</th>\n",
       "      <td>1429</td>\n",
       "      <td>1.158432e+18</td>\n",
       "      <td>14.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565026e+12</th>\n",
       "      <td>1430</td>\n",
       "      <td>1.158428e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565026e+12</th>\n",
       "      <td>1431</td>\n",
       "      <td>1.158428e+18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>10.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565025e+12</th>\n",
       "      <td>1432</td>\n",
       "      <td>1.158426e+18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>10.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1433 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0      tweet_id  positive_sentiment  \\\n",
       "timestamp                                                    \n",
       "1.565106e+12           0  1.158763e+18                 3.0   \n",
       "1.565105e+12           1  1.158762e+18                 9.0   \n",
       "1.565105e+12           2  1.158760e+18                 5.0   \n",
       "1.565105e+12           3  1.158759e+18                 7.0   \n",
       "1.565105e+12           4  1.158759e+18                 3.0   \n",
       "...                  ...           ...                 ...   \n",
       "1.565027e+12        1428  1.158432e+18                 5.0   \n",
       "1.565027e+12        1429  1.158432e+18                14.0   \n",
       "1.565026e+12        1430  1.158428e+18                 3.0   \n",
       "1.565026e+12        1431  1.158428e+18                 5.0   \n",
       "1.565025e+12        1432  1.158426e+18                 2.0   \n",
       "\n",
       "              negative_sentiment  numb_of_mentions  numb_of_urls  \\\n",
       "timestamp                                                          \n",
       "1.565106e+12                19.0               0.0           0.0   \n",
       "1.565105e+12                28.0               0.0           0.0   \n",
       "1.565105e+12                37.0               0.0           0.0   \n",
       "1.565105e+12                47.0               0.0           0.0   \n",
       "1.565105e+12                65.0               0.0           0.0   \n",
       "...                          ...               ...           ...   \n",
       "1.565027e+12                41.0               0.0           0.0   \n",
       "1.565027e+12                44.0               0.0           0.0   \n",
       "1.565026e+12                60.0               0.0           0.0   \n",
       "1.565026e+12                61.0               0.0           0.0   \n",
       "1.565025e+12                65.0               0.0           0.0   \n",
       "\n",
       "              numb_of_hashtagsnumb_of_personal_pronouns  \\\n",
       "timestamp                                                 \n",
       "1.565106e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "...                                                 ...   \n",
       "1.565027e+12                                        0.0   \n",
       "1.565027e+12                                        0.0   \n",
       "1.565026e+12                                        0.0   \n",
       "1.565026e+12                                        0.0   \n",
       "1.565025e+12                                        0.0   \n",
       "\n",
       "              numb_of_present_tenses  numb_of_past_tenses  sent_from_web  ...  \\\n",
       "timestamp                                                                 ...   \n",
       "1.565106e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "...                              ...                  ...            ...  ...   \n",
       "1.565027e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565027e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565026e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565026e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565025e+12                     0.0                  0.0            0.0  ...   \n",
       "\n",
       "              numb_of_intensifiers  tweet_length  userFollowersCount  \\\n",
       "timestamp                                                              \n",
       "1.565106e+12                   0.0          68.0              1592.0   \n",
       "1.565105e+12                   0.0          70.0                33.0   \n",
       "1.565105e+12                   0.0          57.0               220.0   \n",
       "1.565105e+12                   0.0          80.0               106.0   \n",
       "1.565105e+12                   0.0          57.0               550.0   \n",
       "...                            ...           ...                 ...   \n",
       "1.565027e+12                   0.0          93.0               303.0   \n",
       "1.565027e+12                   0.0          92.0                51.0   \n",
       "1.565026e+12                   0.0         256.0               382.0   \n",
       "1.565026e+12                   0.0         209.0               501.0   \n",
       "1.565025e+12                   0.0         208.0               142.0   \n",
       "\n",
       "              userFriendsCount  user_numb_of_tweets  user_list_count  \\\n",
       "timestamp                                                              \n",
       "1.565106e+12             523.0                  0.0             94.0   \n",
       "1.565105e+12               0.0                  0.0              4.0   \n",
       "1.565105e+12              61.0                  0.0              3.0   \n",
       "1.565105e+12             124.0                  0.0              0.0   \n",
       "1.565105e+12             720.0                  0.0              7.0   \n",
       "...                        ...                  ...              ...   \n",
       "1.565027e+12            1465.0                  0.0             11.0   \n",
       "1.565027e+12             272.0                  0.0              4.0   \n",
       "1.565026e+12              16.0                  0.0              4.0   \n",
       "1.565026e+12              74.0                  0.0             19.0   \n",
       "1.565025e+12              11.0                  0.0             14.0   \n",
       "\n",
       "              tfidf_fire  dict_precision  dict_recall  dict_f_measure  \n",
       "timestamp                                                              \n",
       "1.565106e+12         0.0       20.000000    11.110000       14.290000  \n",
       "1.565105e+12         0.0       16.670000    11.110000       13.330000  \n",
       "1.565105e+12         0.0       33.330002    22.219999       26.670000  \n",
       "1.565105e+12         0.0       22.219999    22.219999       22.219999  \n",
       "1.565105e+12         0.0       14.290000    11.110000       12.500000  \n",
       "...                  ...             ...          ...             ...  \n",
       "1.565027e+12         0.0       11.110000    11.110000       11.110000  \n",
       "1.565027e+12         0.0        0.000000     0.000000        0.000000  \n",
       "1.565026e+12         0.0        0.000000     0.000000        0.000000  \n",
       "1.565026e+12         0.0       10.000000    11.110000       10.530000  \n",
       "1.565025e+12         0.0       10.000000    11.110000       10.530000  \n",
       "\n",
       "[1433 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reload the data to check everythings went alright\n",
    "df = pd.read_csv(\"feature_vec.csv\")\n",
    "\n",
    "# Timestamp will need to be reconfigured as index on each load\n",
    "df = df.set_index('timestamp')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['userFollowersCount', 'dict_f_measure']]\n",
    "y = df['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1074, 2)\n",
      "X_test shape: (359, 2)\n",
      "y_train shape: (1074,)\n",
      "y_test shape: (359,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Split the dataset into 'Train' and 'Test' sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### Define and train the model\n",
    "clf = RandomForestClassifier(max_features=2, random_state=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF classifier on training set: 0.95\n",
      "Accuracy of RF classifier on testing set: 0.93\n"
     ]
    }
   ],
   "source": [
    "### Get model accuracy scores\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on testing set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Accuracy of RF classifier on training set: 0.39\n",
    "Accuracy of RF classifier on testing set: 0.20\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=2, random_state=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.15855154e+18]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[0, 0,]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81454733, 0.18545267])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>numb_of_mentions</th>\n",
       "      <th>numb_of_urls</th>\n",
       "      <th>numb_of_hashtagsnumb_of_personal_pronouns</th>\n",
       "      <th>numb_of_present_tenses</th>\n",
       "      <th>numb_of_past_tenses</th>\n",
       "      <th>sent_from_web</th>\n",
       "      <th>...</th>\n",
       "      <th>numb_of_intensifiers</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>userFollowersCount</th>\n",
       "      <th>userFriendsCount</th>\n",
       "      <th>user_numb_of_tweets</th>\n",
       "      <th>user_list_count</th>\n",
       "      <th>tfidf_fire</th>\n",
       "      <th>dict_precision</th>\n",
       "      <th>dict_recall</th>\n",
       "      <th>dict_f_measure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.565106e+12</th>\n",
       "      <td>0</td>\n",
       "      <td>1.158763e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>14.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.158762e+18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>13.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>2</td>\n",
       "      <td>1.158760e+18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>26.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>3</td>\n",
       "      <td>1.158759e+18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>22.219999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.565105e+12</th>\n",
       "      <td>4</td>\n",
       "      <td>1.158759e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0      tweet_id  positive_sentiment  \\\n",
       "timestamp                                                    \n",
       "1.565106e+12           0  1.158763e+18                 3.0   \n",
       "1.565105e+12           1  1.158762e+18                 9.0   \n",
       "1.565105e+12           2  1.158760e+18                 5.0   \n",
       "1.565105e+12           3  1.158759e+18                 7.0   \n",
       "1.565105e+12           4  1.158759e+18                 3.0   \n",
       "\n",
       "              negative_sentiment  numb_of_mentions  numb_of_urls  \\\n",
       "timestamp                                                          \n",
       "1.565106e+12                19.0               0.0           0.0   \n",
       "1.565105e+12                28.0               0.0           0.0   \n",
       "1.565105e+12                37.0               0.0           0.0   \n",
       "1.565105e+12                47.0               0.0           0.0   \n",
       "1.565105e+12                65.0               0.0           0.0   \n",
       "\n",
       "              numb_of_hashtagsnumb_of_personal_pronouns  \\\n",
       "timestamp                                                 \n",
       "1.565106e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "1.565105e+12                                        0.0   \n",
       "\n",
       "              numb_of_present_tenses  numb_of_past_tenses  sent_from_web  ...  \\\n",
       "timestamp                                                                 ...   \n",
       "1.565106e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "1.565105e+12                     0.0                  0.0            0.0  ...   \n",
       "\n",
       "              numb_of_intensifiers  tweet_length  userFollowersCount  \\\n",
       "timestamp                                                              \n",
       "1.565106e+12                   0.0          68.0              1592.0   \n",
       "1.565105e+12                   0.0          70.0                33.0   \n",
       "1.565105e+12                   0.0          57.0               220.0   \n",
       "1.565105e+12                   0.0          80.0               106.0   \n",
       "1.565105e+12                   0.0          57.0               550.0   \n",
       "\n",
       "              userFriendsCount  user_numb_of_tweets  user_list_count  \\\n",
       "timestamp                                                              \n",
       "1.565106e+12             523.0                  0.0             94.0   \n",
       "1.565105e+12               0.0                  0.0              4.0   \n",
       "1.565105e+12              61.0                  0.0              3.0   \n",
       "1.565105e+12             124.0                  0.0              0.0   \n",
       "1.565105e+12             720.0                  0.0              7.0   \n",
       "\n",
       "              tfidf_fire  dict_precision  dict_recall  dict_f_measure  \n",
       "timestamp                                                              \n",
       "1.565106e+12         0.0       20.000000    11.110000       14.290000  \n",
       "1.565105e+12         0.0       16.670000    11.110000       13.330000  \n",
       "1.565105e+12         0.0       33.330002    22.219999       26.670000  \n",
       "1.565105e+12         0.0       22.219999    22.219999       22.219999  \n",
       "1.565105e+12         0.0       14.290000    11.110000       12.500000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['userFollowersCount', 'dict_f_measure']]\n",
    "y = df['tweet_id']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
